{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9214bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kshit\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\kshit\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\kshit\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "import spacy\n",
    "import openai\n",
    "import random\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "from datetime import date,timedelta\n",
    "from bertopic import BERTopic\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3657df",
   "metadata": {},
   "source": [
    "# jsonl -> dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9e38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_phdf(client,jsonl_name): #'P1_all.jsonl'\n",
    "    #Opening the input Doccano Jsonl file\n",
    "    with open(jsonl_name, 'r', encoding=\"utf8\") as json_file:\n",
    "        json_list = list(json_file)\n",
    "        \n",
    "    #Appending the jsonObjects in a dataframe\n",
    "    jos=[]\n",
    "    for i in range(len(json_list)):\n",
    "        jsonObject = json.loads(json_list[i])\n",
    "        jos.append(jsonObject)\n",
    "    \n",
    "    cl = {'P4':'entities','P1':'label'}\n",
    "    \n",
    "    #DataFrame is made to remove the reviews which are passed in gpt3 multiple times.\n",
    "    #We're taking those reviews which have most number of phrases extracted\n",
    "    jos = pd.DataFrame(jos)\n",
    "    jos = jos[jos[cl[client]].apply(lambda x:len(x))!=0]\n",
    "    jos['nl'] = jos[cl[client]].apply(lambda x:len(x))\n",
    "    jos = jos.sort_values(['id','nl']).drop_duplicates(['id'],keep='last')\n",
    "    \n",
    "    #Generating final phrase dataframe\n",
    "    resultList = []\n",
    "    for i in jos.index:\n",
    "        jsonObject = jos.loc[i]\n",
    "        for start, end, category in jos[cl[client]][i]:\n",
    "            result = {}\n",
    "            result[\"Review\"] = jos[\"text\"][i]\n",
    "            \n",
    "            #Client specific operations are done here due to difference in Doccano Files.\n",
    "            if client=='P1':\n",
    "                result[\"Review ID\"] = str(jos[\"id\"][i])\n",
    "                result[\"Date\"] = jos[\"date\"][i]\n",
    "                result[\"Rating\"] = int(jos[\"rating\"][i].split()[0])\n",
    "            elif client=='P4':\n",
    "                result[\"Review ID\"] = 'P4R'+str(jos[\"id\"][i])\n",
    "                result[\"Date\"] = jsonObject[\"Date\"]\n",
    "                result[\"Rating\"] = int(jsonObject[\"Rating\"].split()[0])\n",
    "                \n",
    "            result[\"Aspect\"] = category.split(\"_\")[0].strip()\n",
    "            if category.split(\"_\")[1].lower() == \"neg\":\n",
    "                result[\"Sentiment\"] = \"Negative\"\n",
    "                result[\"Phrase\"] = jos[\"text\"][i][start:end].strip()\n",
    "            elif category.split(\"_\")[1].lower() == \"pos\":\n",
    "                result[\"Sentiment\"] = \"Positive\"\n",
    "                result[\"Phrase\"] = jos[\"text\"][i][start:end].strip()\n",
    "            resultList.append(result)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(resultList, orient='columns')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a1b0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = jsonl_to_phdf(client='P1',jsonl_name='P1_all.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6c1c100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_df_20230105.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.columns = ['Review ID','Review','Aspect','Sentiment','Phrase']\n",
    "df = sampling(df,method='manual',value=350)\n",
    "df['Aspect'] = df['Aspect'].apply(lambda x:str(x.capitalize()))\n",
    "df['Sentiment'] = df['Sentiment'].astype(str)\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x:str(x.capitalize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99134d64",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f8981304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(df,value=100,method='mean',stdev=0):\n",
    "    df['cnt'] = df.groupby(['Review ID']).transform(\"count\")['Phrase'] #Number of Phrases corresponding to each Review\n",
    "    \n",
    "    if method=='mean': #Balancing using mean number of phrases per aspect\n",
    "        x = round(len(df)/df.Aspect.nunique()+stdev*np.std(df.Aspect.value_counts()))\n",
    "    elif method=='manual': #Balaning aspects using some specific value\n",
    "        x = value\n",
    "    \n",
    "    #storing the aspects which are unbalanced\n",
    "    l = []\n",
    "    for aspect in df.Aspect.unique():\n",
    "        if len(df[df.Aspect==aspect])>x:\n",
    "            l.append(aspect)\n",
    "    \n",
    "    \n",
    "    dfs = []\n",
    "    cnt = df['cnt'].min()\n",
    "    #For unbalanced aspects, First we will take the reviews with minimum number of phrases, then increase the count of phrases\n",
    "    #until the threshold 'x' is met. This is basically a Greedy Approach.\n",
    "    for aspect in l:\n",
    "        temp_cnt=cnt\n",
    "        while len(df[(df.Aspect==aspect)&(df.cnt<=temp_cnt)])<x:\n",
    "            temp_cnt+=1\n",
    "    #     print(aspect,temp_cnt,len(df[(df.Aspect==aspect)&(df.cnt<=temp_cnt)]))\n",
    "        dfs.append(df[(df.Aspect==aspect)&(df.cnt<=temp_cnt)].sample(n=x,random_state=1))\n",
    "    \n",
    "    #At last we will remove the unbalanced aspects & append the balanced aspects to the original dataframe\n",
    "    df = df[~df['Aspect'].isin(l)]\n",
    "    for i in dfs:\n",
    "        df = df.append(i)\n",
    "\n",
    "    df['Aspect'] = df['Aspect'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7170bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cnt'] = df.groupby(['Review ID']).transform(\"count\")['Phrase']\n",
    "\n",
    "cvg = df[(df.Aspect=='Coverage')&(df.cnt<=3)].sample(n=99,random_state=1)\n",
    "ti = df[(df.Aspect=='Time')&(df.cnt<=4)].sample(n=99,random_state=6)\n",
    "fi = df[(df.Aspect=='Finish')&(df.cnt<=3)].sample(n=99,random_state=12)\n",
    "sk = df[df.Aspect=='Skin'].sample(n=99,random_state=1)\n",
    "\n",
    "df = df[~df['Aspect'].isin(['Coverage','Time','Finish','Skin'])]\n",
    "df = df.append(cvg)\n",
    "df = df.append(ti)\n",
    "df = df.append(fi)\n",
    "df = df.append(sk)\n",
    "df['Aspect'] = df['Aspect'].astype(str)\n",
    "\n",
    "for i in df.index:\n",
    "    if df['Aspect'][i]=='Comp':\n",
    "        df['Aspect'][i] = 'Competitor'\n",
    "    if df['Aspect'][i]=='Demo':\n",
    "        df['Aspect'][i] = 'Demographic'\n",
    "df.drop(219,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d64321",
   "metadata": {},
   "source": [
    "# dataframe -> txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a2cc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase dataframe to txt file creation\n",
    "def phdf_to_txt(df):\n",
    "    s = ''\n",
    "    for id in df['Review ID'].unique():\n",
    "    #     s = s + '##'+id+'\\n'\n",
    "    #These '##' & '\\n\\n\\n' strings are added as per the text file format which was required to generate\n",
    "        s = s + '##'\n",
    "        s = s + list(df[df['Review ID']==id]['Review'])[0]+'\\n\\n\\n'\n",
    "        r = random.randint(1,10)\n",
    "        if r%2==0:\n",
    "            senti = ['Positive','Negative']\n",
    "        else:\n",
    "            senti = ['Negative','Positive']\n",
    "\n",
    "        for sentiment in senti:\n",
    "            s = s+sentiment.capitalize()+': \\n' #For same naming everywhere I am using 'capitalized' sentiments and aspects\n",
    "            df1 = df[(df['Review ID']==id)]\n",
    "            if len(df1[df1.Sentiment==sentiment])==0:\n",
    "                s = s+'None\\n'\n",
    "            else:\n",
    "                df1 = df1[(df1.Sentiment==sentiment)]\n",
    "                for aspect in df1['Aspect'].unique():\n",
    "                    s = s + aspect.capitalize()+': '\n",
    "                    l = list(df1[df1.Aspect==aspect]['Phrase'])\n",
    "                    if len(l)==1:\n",
    "                        s = s + l[0] + '\\n'\n",
    "                    else:\n",
    "                        for phrase in l:\n",
    "                            s = s + phrase + ', '\n",
    "                        s = s[:-2] #To remove last ', ' string\n",
    "                        s+='\\n'\n",
    "            if sentiment==senti[0]:\n",
    "                s = s+'\\n'\n",
    "\n",
    "    text_file = open(\"data.txt\", \"w\",encoding=\"utf8\") \n",
    "    text_file.write(s)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76c6d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "phdf_to_txt(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e25276",
   "metadata": {},
   "source": [
    "# txt -> jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ba796846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is the txt file really needed?\n",
    "def txt_to_jsonl(jsonl_name): #\"gpt3_train_20230111v1.jsonl\"\n",
    "    txt = open(r\"data.txt\",\"r\",encoding=\"utf8\")\n",
    "    s = txt.read()\n",
    "\n",
    "    #string cleaning\n",
    "    while(s[0]!='#'):\n",
    "        s = s[1:]\n",
    "\n",
    "    l = s.split('##')\n",
    "    l.pop(0)\n",
    "\n",
    "    prompt = []\n",
    "    completion = []\n",
    "\n",
    "    for i in range(len(l)):\n",
    "        prompt.append(l[i].split('\\n\\n\\n')[0])\n",
    "        completion.append(l[i].split('\\n\\n\\n')[1])\n",
    "\n",
    "    data = pd.DataFrame(list(zip(prompt, completion)), columns =['prompt', 'completion'])\n",
    "    data['prompt'] = ' ' + data['prompt'] + '\\n\\n###\\n\\n'\n",
    "    data['completion'] = ' ' + data['completion'] + ' END'\n",
    "\n",
    "    data.to_json(jsonl_name,orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "494e7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_to_jsonl('gpt3_train_20230117v1.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7598b",
   "metadata": {},
   "source": [
    "# Summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c40d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df,xlsx_name): #\"1428_phrases_summary.xlsx\"\n",
    "    x = pd.DataFrame(df.groupby(['Aspect','Sentiment']).count()['Phrase']) #Phrase Count per aspect per sentiment\n",
    "    x.columns = ['phrase_count']\n",
    "    y = df.groupby(['Aspect','Sentiment']).mean() #Average Phrase Rating per aspect per sentiment\n",
    "    y.columns = ['phrase_avg_rating']\n",
    "\n",
    "    final_df = x.join(y)\n",
    "    final_df = final_df.reset_index()\n",
    "\n",
    "    final_df['review_avg_rating']=''\n",
    "    final_df['review_count']=''\n",
    "    for aspect in final_df.Aspect.unique():\n",
    "        for senti in ['Negative','Positive']:\n",
    "            for i in final_df[(final_df['Aspect']==aspect)&(final_df['Sentiment']==senti)].index:\n",
    "                final_df['review_count'][i]=df[(df['Aspect']==aspect)&(df['Sentiment']==senti)].Review.nunique()\n",
    "                final_df['review_avg_rating'][i]=df[(df['Aspect']==aspect)&(df['Sentiment']==senti)].drop_duplicates(['Review ID']).mean()[0]\n",
    "    final_df.to_excel(xlsx_name,index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a010e76",
   "metadata": {},
   "source": [
    "# Fine Tuning GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a20e621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Creation to generate completion\n",
    "df = pd.read_csv('P4 First Aid Beauty.csv')\n",
    "df = df[:300]\n",
    "df.fillna('',inplace=True)\n",
    "df['prompt'] = ' '+df['Review Title']+'\\n\\n'+df['Review']+'\\n\\n###\\n\\n'\n",
    "df['completion']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39626179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing API Keys in Environment\n",
    "API_KEY = \"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\"\n",
    "ORG = \"org-h6Tn46yKPTtZxoUF37AccEF0\"\n",
    "os.environ['OPENAI_API_KEY'] = API_KEY\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2bdce1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#Data Preparation Step\n",
    "!openai tools fine_tunes.prepare_data -f gpt3_train_20230117v1.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tuning Step\n",
    "!openai api fine_tunes.create -t \"gpt3_train_20230111v2.jsonl\" -m \"davinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03c033e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Positive: \n",
      "Odor: pleasant\n",
      "\n",
      "Negative: \n",
      "Value: raised the price\n",
      "Ingredients: catastrophic change\n",
      "1  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: wish I bought more\n",
      "Skin: winter dryness\n",
      "2  Negative: \n",
      "Ingredients: eucalyptus\n",
      "Finish: didn't leave me moisturized\n",
      "\n",
      "Positive: \n",
      "None\n",
      "3  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Value: $78 for a 14oz jar?\n",
      "Purchase: I cancelled it\n",
      "4  Positive: \n",
      "Emotion: love this moisturizer\n",
      "\n",
      "Negative: \n",
      "None\n",
      "5  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: must-have product\n",
      "Application: works well\n",
      "Time: long-lasting results\n",
      "6  Positive: \n",
      "Application: feels so nice!\n",
      "Value: worth the price\n",
      "Skin: smoother my skin got\n",
      "\n",
      "Negative: \n",
      "None\n",
      "7  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: must have in winter\n",
      "Family: whole family\n",
      "Time: during winter time\n",
      "8  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Emotion: honestly this stuff is not as moisturizing\n",
      "Value: rip off\n",
      "Application: makeup pill like crazy\n",
      "Skin: retinol irritation\n",
      "9  Negative: \n",
      "Value: basically cerave\n",
      "\n",
      "Positive: \n",
      "None\n",
      "10  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: always lasts\n",
      "Skin: skin feel\n",
      "11  Positive: \n",
      "Purchase: MUST HAVE\n",
      "Skin: oil-dry skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "12  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: not just moisturized, but nourished\n",
      "Emotion: love\n",
      "13  Negative: \n",
      "Application: peels right off\n",
      "\n",
      "Positive: \n",
      "Moisturizing: very moisturizing\n",
      "14  Positive: \n",
      "Odor: doesn’t have a scent\n",
      "Skin: hydrated and smooth.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "15  Positive: \n",
      "Value: for the price, it’s a fantastic formula\n",
      "\n",
      "Negative: \n",
      "None\n",
      "16  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Emotion: not for me anymore\n",
      "17  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: MUST BUY!\n",
      "Skin: dry to normal skin\n",
      "18  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: holy grail\n",
      "Skin: had difficulties, dry patches\n",
      "19  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: wouldn't recommend\n",
      "Skin: skin to burn\n",
      "20  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: Ultra Repair cream\n",
      "Application: super creamy, hydrating,\n",
      "Skin: dry skin\n",
      "21  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: love it\n",
      "Skin: body cream\n",
      "22  Positive: \n",
      "Emotion: love skincare\n",
      "\n",
      "Negative: \n",
      "None\n",
      "23  Positive: \n",
      "Emotion: LOVE LOVE LOVE\n",
      "Application: so smooth\n",
      "\n",
      "Negative: \n",
      "None\n",
      "24  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: MUST Have\n",
      "Skin: no redness no breakouts\n",
      "25  Positive: \n",
      "Application: rubs on nicely\n",
      "Skin: no signs of acne or bumps\n",
      "\n",
      "Negative: \n",
      "None\n",
      "26  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Time: night cream\n",
      "Skin: combo skin\n",
      "27  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: bottle will last me MONTHS\n",
      "Skin: super dry skin\n",
      "28  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: don’t recommend, will not be purchasing\n",
      "Odor: smell\n",
      "29  Positive: \n",
      "Odor: no fragrance\n",
      "\n",
      "Negative: \n",
      "None\n",
      "30  Positive: \n",
      "Emotion: love this stuff\n",
      "Skin: skin barrier\n",
      "\n",
      "Negative: \n",
      "None\n",
      "31  Positive: \n",
      "Emotion: love it\n",
      "Purchase: definitely be purchasing again\n",
      "\n",
      "Negative: \n",
      "None\n",
      "32  Positive: \n",
      "Emotion: i’ve heard nothing but good things\n",
      "\n",
      "Negative: \n",
      "Application: my skin felt like it was burning\n",
      "Skin: my skin barrier has healed\n",
      "33  Negative: \n",
      "Ingredients: silicones\n",
      "Emotion: outright hated\n",
      "Time: lasted me such a short time\n",
      "\n",
      "Positive: \n",
      "None\n",
      "34  Positive: \n",
      "Brand: finally pulled the trigger\n",
      "Partner: pure skin face cleanser\n",
      "Skin: my skin has started to look amazing\n",
      "\n",
      "Negative: \n",
      "None\n",
      "35  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: very soothing and moisturizing\n",
      "36  Positive: \n",
      "Skin: stable condition\n",
      "\n",
      "Negative: \n",
      "None\n",
      "37  Positive: \n",
      "Emotion: absolutely love\n",
      "Application: doesn’t feel too heavy\n",
      "\n",
      "Negative: \n",
      "None\n",
      "38  Positive: \n",
      "Emotion: it’s really good\n",
      "\n",
      "Negative: \n",
      "None\n",
      "39  Positive: \n",
      "Emotion: best moisturizer\n",
      "Application: doesn’t feel heavy\n",
      "\n",
      "Negative: \n",
      "None\n",
      "40  Positive: \n",
      "Emotion: love it.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "41  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: on first application\n",
      "Skin: chaffing areas\n",
      "42  Positive: \n",
      "Value: you absolutely get your money's worth\n",
      "Application: layers fine\n",
      "\n",
      "Negative: \n",
      "None\n",
      "43  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: disappointed\n",
      "Skin: skin has gotten a bit drier\n",
      "44  Positive: \n",
      "Skin: hydration, texture\n",
      "\n",
      "Negative: \n",
      "None\n",
      "45  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: actually a huge bottle so it will last ages\n",
      "46  Positive: \n",
      "Purchase: continue to repurchase\n",
      "Skin: eczema prone\n",
      "\n",
      "Negative: \n",
      "None\n",
      "47  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: stay away\n",
      "Skin: acne prone skin\n",
      "48  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: excellent bang for your buck\n",
      "Ingredients: know how to deliver\n",
      "49  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: i love this moisturizer\n",
      "Application: use it at night\n",
      "50  Negative: \n",
      "Value: overpriced\n",
      "Skin: breakout\n",
      "\n",
      "Positive: \n",
      "None\n",
      "51  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: face no long feels dry\n",
      "52  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: holy grail\n",
      "53  Positive: \n",
      "Value: win win\n",
      "\n",
      "Negative: \n",
      "None\n",
      "54  Positive: \n",
      "Purchase: best purchase\n",
      "Skin: soft moisturized skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "55  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Emotion: burns like really bad\n",
      "Application: pills\n",
      "56  Positive: \n",
      "Application: doesn't pill\n",
      "Partner: Josie Maran argan milk\n",
      "\n",
      "Negative: \n",
      "None\n",
      "57  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: one of the best moisturizers\n",
      "Skin: oily skin\n",
      "58  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Ingredients: changed their formula\n",
      "Finish: burns\n",
      "59  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: eczema patches\n",
      "60  Positive: \n",
      "Emotion: extremely moisturizing\n",
      "\n",
      "Negative: \n",
      "Skin: greasy for summer\n",
      "61  Positive: \n",
      "Odor: doesn’t have a smell\n",
      "Application: layer makeup nicely\n",
      "Skin: dry and very sensitive\n",
      "\n",
      "Negative: \n",
      "None\n",
      "62  Negative: \n",
      "Application: product would end up pilling off of my skin\n",
      "Emotion: disappointed\n",
      "\n",
      "Positive: \n",
      "None\n",
      "63  Positive: \n",
      "Value: decent price\n",
      "Ingredients: add squalane\n",
      "Skin: my very dry skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "64  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: smooth out my arms\n",
      "65  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: parched skin from drying out\n",
      "66  Negative: \n",
      "Odor: product is no longer fragrance free\n",
      "Skin: super sensitive, rosacea prone skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "67  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: Great product!\n",
      "Application: didn’t peel!\n",
      "Skin: moisturizer my skin.\n",
      "Competitor: sunburns and even\n",
      "68  Positive: \n",
      "Value: cost effective\n",
      "Purchase: reordering\n",
      "Skin: normal skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "69  Negative: \n",
      "Skin: burning sensation, my face would turn blotchy\n",
      "\n",
      "Positive: \n",
      "None\n",
      "70  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Ingredients: first aid beauty if by any chance you’re reading sephora reviews please remove the eucalyptus oil from this moisturizer\n",
      "71  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: 10/10\n",
      "Purchase: prefer the bottle formulation\n",
      "Skin: dry patches\n",
      "72  Positive: \n",
      "Emotion: best moisturizer EVER\n",
      "Application: for your hands\n",
      "Skin: soothe my acne\n",
      "\n",
      "Negative: \n",
      "None\n",
      "73  Positive: \n",
      "Emotion: awesome!!\n",
      "\n",
      "Negative: \n",
      "None\n",
      "74  Negative: \n",
      "Motivation: wrong product for my skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "75  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Feel: feel so nice\n",
      "76  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Ingredients: nice ingredient list/formula\n",
      "Value: significantly less expensive\n",
      "Skin: skin, very nice\n",
      "77  Negative: \n",
      "Odor: smells like vomit\n",
      "Purchase: would not purchase\n",
      "Skin: weird waxy coating\n",
      "\n",
      "Positive: \n",
      "None\n",
      "78  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: great product for the price\n",
      "Skin: very moisturizing\n",
      "79  Positive: \n",
      "Odor: no irritating fragrance\n",
      "Skin: baby smooth.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "80  Positive: \n",
      "Motivation: buy again\n",
      "Skin: my skin isn't as dry.\n",
      "\n",
      "Negative: \n",
      "Demographic: when my eczema is tamed\n",
      "81  Negative: \n",
      "Purchase: returning this ASAP.\n",
      "Skin: doesn’t actually moisturize\n",
      "\n",
      "Positive: \n",
      "None\n",
      "82  Positive: \n",
      "Purchase: recommend!\n",
      "Value: better products for price\n",
      "\n",
      "Negative: \n",
      "None\n",
      "83  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Brand: worst cream\n",
      "Application: irritates my skin\n",
      "Competitor: stick to Kiehls and Clinique.\n",
      "84  Positive: \n",
      "Purchase: would definitely recommend\n",
      "\n",
      "Negative: \n",
      "None\n",
      "85  Negative: \n",
      "Application: pills\n",
      "Skin: super dry skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "86  Positive: \n",
      "Competitor: taking away the redness\n",
      "\n",
      "Negative: \n",
      "None\n",
      "87  Negative: \n",
      "Application: wasn't as moisturizing\n",
      "Purchase: give this one a pass\n",
      "\n",
      "Positive: \n",
      "None\n",
      "88  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: consistently happy\n",
      "Quality: good quality\n",
      "89  Positive: \n",
      "Purchase: worth it\n",
      "Emotion: luxurious\n",
      "Skin: hydrated\n",
      "\n",
      "Negative: \n",
      "None\n",
      "90  Negative: \n",
      "Application: burns when I put it on\n",
      "\n",
      "Positive: \n",
      "None\n",
      "91  Positive: \n",
      "Emotion: love this face cream\n",
      "Partner: Youth To The People\n",
      "\n",
      "Negative: \n",
      "None\n",
      "92  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: price for the amount is reasonable\n",
      "Skin: dry and sensitive skin\n",
      "93  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: aging combination skin\n",
      "94  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: littler bit basic for the price\n",
      "Skin: oily skin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Ingredients: reformulated\n",
      "Emotion: doesn’t feel the same\n",
      "96  Negative: \n",
      "Purchase: made me breakout\n",
      "Skin: acne prone skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "97  Positive: \n",
      "Emotion: love it\n",
      "\n",
      "Negative: \n",
      "None\n",
      "98  Negative: \n",
      "Application: face break out\n",
      "Skin: my entire face break out\n",
      "\n",
      "Positive: \n",
      "None\n",
      "99  Positive: \n",
      "Skin: hydrated without making me oily\n",
      "\n",
      "Negative: \n",
      "None\n",
      "100  Positive: \n",
      "Brand: love this fab moisturizing cream\n",
      "Purchase: will continue to purchase\n",
      "Skin: not sticky\n",
      "\n",
      "Negative: \n",
      "None\n",
      "101  Negative: \n",
      "Emotion: favorite moisturizer\n",
      "\n",
      "Positive: \n",
      "Time: sinks in as fast\n",
      "102  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Design: feels like a little too much\n",
      "Skin: normal sensitive skin\n",
      "103  Negative: \n",
      "Odor: petro chemical fishy mold\n",
      "Emotion: moving on to a more reliable\n",
      "\n",
      "Positive: \n",
      "None\n",
      "104  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: not hydrating at all\n",
      "Skin: my skin feels so dry\n",
      "Competitor: Farmacy Halo Honey and Dewy Skin\n",
      "105  Positive: \n",
      "Competitor: “water bank” by Tatcha\n",
      "\n",
      "Negative: \n",
      "None\n",
      "106  Positive: \n",
      "Application: dry and then use an oil based primer\n",
      "Value: more lasting\n",
      "\n",
      "Negative: \n",
      "None\n",
      "107  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: will not be purchasing again\n",
      "Value: not worth the price\n",
      "Skin: feels very tacky\n",
      "108  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: worth it\n",
      "Time: only cream I’ve encountered\n",
      "109  Negative: \n",
      "Purchase: would not have purchased if I knew\n",
      "Ingredients: squeeze tubes that do not require\n",
      "\n",
      "Positive: \n",
      "None\n",
      "110  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Time: keeps my skin moisturized for the whole day.\n",
      "111  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: worth the hype\n",
      "Purchase: will repurchase again\n",
      "Skin: sensitive skin\n",
      "112  Negative: \n",
      "Application: pills over and under anything\n",
      "Skin: dry, sensitive winter skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "113  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: product I received was not these two tubes\n",
      "114  Positive: \n",
      "Odor: doesn't break me out\n",
      "Skin: soft\n",
      "\n",
      "Negative: \n",
      "None\n",
      "115  Positive: \n",
      "Emotion: would make your face burn\n",
      "\n",
      "Negative: \n",
      "None\n",
      "116  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: skin was dry flaky itchy and red\n",
      "Product: great product\n",
      "117  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: won’t buy again\n",
      "118  Negative: \n",
      "Emotion: ruined my skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "119  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Finish: not make me blotchy red\n",
      "Skin: dry & sensitive skin approved\n",
      "120  Negative: \n",
      "Purchase: won't repurchase\n",
      "Application: thick, making my skin clog\n",
      "\n",
      "Positive: \n",
      "None\n",
      "121  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: less dry\n",
      "122  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: love that\n",
      "Skin: my skin felt much more hydrated, my redness has gone down\n",
      "123  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: love it!\n",
      "Application: apply it lightly in the summer\n",
      "Emotion: significantly less breakouts\n",
      "124  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: affordable\n",
      "Skin: oily/acne prone skin\n",
      "125  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: easy to apply, absorbs quickly\n",
      "Value: worth it.\n",
      "126  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Motivation: different packaging\n",
      "127  Positive: \n",
      "Value: amazing find that is loads more affordable\n",
      "Skin: non irritating\n",
      "\n",
      "Negative: \n",
      "None\n",
      "128  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Competitor: save it for dry hands, elbows, etc.!\n",
      "Skin: sensitive moisturizer\n",
      "129  Positive: \n",
      "Value: it’s so worth\n",
      "Purchase: bought more\n",
      "\n",
      "Negative: \n",
      "None\n",
      "130  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: love this product\n",
      "Skin: for my legs and feet\n",
      "131  Positive: \n",
      "Emotion: getting so many compliments\n",
      "Application: absorbs FAST\n",
      "\n",
      "Negative: \n",
      "None\n",
      "132  Negative: \n",
      "Motivation: sad and full of acne\n",
      "Skin: burning I was feeling was not good\n",
      "\n",
      "Positive: \n",
      "None\n",
      "133  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: be returning it\n",
      "Skin: peels\n",
      "134  Positive: \n",
      "Motivation: love love love\n",
      "Emotion: perfect\n",
      "\n",
      "Negative: \n",
      "None\n",
      "135  Positive: \n",
      "Purchase: got my mom hooked\n",
      "Skin: sensitive, combo skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "136  Positive: \n",
      "Skin: dry winter days\n",
      "\n",
      "Negative: \n",
      "None\n",
      "137  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: definitely repurchase\n",
      "Skin: hydration\n",
      "138  Negative: \n",
      "Value: better out there\n",
      "Emotion: overhyped, it’s just not that good\n",
      "\n",
      "Positive: \n",
      "None\n",
      "139  Negative: \n",
      "Emotion: gave me the worse breakout\n",
      "\n",
      "Positive: \n",
      "None\n",
      "140  Positive: \n",
      "Emotion: LOVE this\n",
      "Ingredients: had no reactions\n",
      "Purchase: prefer the tube\n",
      "\n",
      "Negative: \n",
      "None\n",
      "141  Positive: \n",
      "Purchase: product might be for everyone, but I'm sold\n",
      "Skin: lizard skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "142  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Emotion: oily\n",
      "143  Positive: \n",
      "Emotion: glad I found it.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "144  Positive: \n",
      "Purchase: holy grail\n",
      "Reduce: redness\n",
      "\n",
      "Negative: \n",
      "None\n",
      "145  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: went back the next day\n",
      "Skin: winter skin\n",
      "146  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: favorite moisturizer\n",
      "Skin: painful dry patches\n",
      "147  Negative: \n",
      "Odor: weird minty smell\n",
      "Application: doesn’t really moisturize\n",
      "\n",
      "Positive: \n",
      "None\n",
      "148  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: couldn’t say enough good things\n",
      "Application: perfect consistency\n",
      "Value: great price\n",
      "Skin: sensitive acne prone skin\n",
      "149  Negative: \n",
      "Odor: smell leaves something to be desired.\n",
      "\n",
      "Positive: \n",
      "Skin: done wonders for my dry skin\n",
      "150  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: holy grails\n",
      "Application: thick cream\n",
      "151  Positive: \n",
      "Emotion: really like this product\n",
      "\n",
      "Negative: \n",
      "None\n",
      "152  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: should have purchased two bottles\n",
      "Skin: hands not look old\n",
      "153  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: godsend\n",
      "Application: light\n",
      "Odor: pleasant scent\n",
      "154  Negative: \n",
      "Odor: smells sunscreen\n",
      "\n",
      "Positive: \n",
      "Application: a little goes a long way\n",
      "155  Negative: \n",
      "Odor: smells like sunscreen\n",
      "Application: rub to get it to absorb\n",
      "Ingredients: changed their formula\n",
      "\n",
      "Positive: \n",
      "None\n",
      "156  Positive: \n",
      "Application: smooth to apply\n",
      "Emotion: good product.\n",
      "\n",
      "Negative: \n",
      "Price: love the price\n",
      "157  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: no frills face cream\n",
      "Skin: dryness\n",
      "158  Negative: \n",
      "Purchase: i got the keihls one instead\n",
      "Skin: broke me out\n",
      "\n",
      "Positive: \n",
      "None\n",
      "159  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: overall cost is much better\n",
      "Partner: Peptide Moisturizer,\n",
      "Motivation: asked a Sephora employee\n",
      "160  Negative: \n",
      "Emotion: Wrecked my skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "161  Negative: \n",
      "Application: scrubbed it off\n",
      "Skin: my skin started burning\n",
      "\n",
      "Positive: \n",
      "None\n",
      "162  Negative: \n",
      "Application: feels weird on skin, clings to the moisturizer\n",
      "Ingredients: changed their formula\n",
      "Value: returning though\n",
      "\n",
      "Positive: \n",
      "Skin: my acne has cleared up, some of my redness has faded\n",
      "163  Positive: \n",
      "Purchase: worth every single penny\n",
      "Value: value size will go on sale\n",
      "\n",
      "Negative: \n",
      "None\n",
      "164  Negative: \n",
      "Odor: weird smell\n",
      "\n",
      "Positive: \n",
      "Hydrating: super hydrating\n",
      "165  Negative: \n",
      "Ingredients: ingredient\n",
      "Value: good value\n",
      "Skin: my face\n",
      "\n",
      "Positive: \n",
      "None\n",
      "166  Negative: \n",
      "Competitor: lots of other products out there\n",
      "Finish: dries up so quickly, my morning\n",
      "\n",
      "Positive: \n",
      "None\n",
      "167  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: unbelievable good\n",
      "Application: not sticky/oily/chunky\n",
      "Skin: dry area\n",
      "168  Negative: \n",
      "Finish: dry cast\n",
      "\n",
      "Positive: \n",
      "None\n",
      "169  Positive: \n",
      "Finish: skin?\n",
      "\n",
      "Negative: \n",
      "None\n",
      "170  Positive: \n",
      "Emotion: love this product\n",
      "Skin: sensitive skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "171  Positive: \n",
      "Emotion: love this holy grail\n",
      "\n",
      "Negative: \n",
      "None\n",
      "172  Negative: \n",
      "Motivation: product on social media\n",
      "\n",
      "Positive: \n",
      "None\n",
      "173  Positive: \n",
      "Texture: lightweight texture\n",
      "\n",
      "Negative: \n",
      "Skin: broke me out\n",
      "174  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Value: returning this!!!\n",
      "175  Negative: \n",
      "Value: lmportant, in my opinion,\n",
      "Motivation: all of the hype\n",
      "\n",
      "Positive: \n",
      "None\n",
      "176  Negative: \n",
      "Application: have to tap/rub it in gently\n",
      "\n",
      "Positive: \n",
      "Skin: skin feels very soft and supple\n",
      "177  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: will buy full size\n",
      "178  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: not hydrating enough\n",
      "Season: not hydrating enough in the winter\n",
      "179  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: Best Moisturizer Ever\n",
      "Application: through my adjustment\n",
      "Skin: dry, flaky skin\n",
      "180  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: product is just okay.\n",
      "Absorb: didn't do it for me.\n",
      "Skin: dry skin\n",
      "181  Positive: \n",
      "Emotion: amazing for dry skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "182  Positive: \n",
      "Emotion: wow!\n",
      "Application: never felt dry\n",
      "\n",
      "Negative: \n",
      "None\n",
      "183  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: love this product\n",
      "Application: use this product overnight\n",
      "Skin: skin feels amazing\n",
      "184  Positive: \n",
      "Application: absorbs any where\n",
      "Skin: dry patches\n",
      "\n",
      "Negative: \n",
      "None\n",
      "185  Positive: \n",
      "Emotion: it’s been on the dry side\n",
      "\n",
      "Negative: \n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186  Positive: \n",
      "Skin: sensitive skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "187  Negative: \n",
      "Ingredients: eucalyptus\n",
      "\n",
      "Positive: \n",
      "None\n",
      "188  Positive: \n",
      "Motivation: better one without silicones\n",
      "\n",
      "Negative: \n",
      "Ingredients: dimethicone\n",
      "189  Positive: \n",
      "Emotion: incredible product\n",
      "Skin: sensitive skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "190  Positive: \n",
      "Purchase: go-to moisturizer\n",
      "Skin: irritated, cracked skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "191  Positive: \n",
      "Demographic: I use this morning and night\n",
      "\n",
      "Negative: \n",
      "None\n",
      "192  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: favorite moisturizer\n",
      "Purchase: worth the purchase\n",
      "193  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: lucky find\n",
      "Finish: plump without being greasy\n",
      "194  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: nourish the skin\n",
      "Ingredients: great ingredients\n",
      "Application: sinks in well\n",
      "195  Positive: \n",
      "Application: nice cooling affect\n",
      "Skin: dry skin feel moisturized\n",
      "\n",
      "Negative: \n",
      "None\n",
      "196  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: worth the price tag\n",
      "Skin: rough areas\n",
      "197  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: Won’t Be Repurchasing\n",
      "Ingredients: pills\n",
      "198  Positive: \n",
      "Purchase: would have paid the full price\n",
      "Skin: drink skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "199  Negative: \n",
      "Emotion: worst breakouts\n",
      "Skin: ruined my skin\n",
      "\n",
      "Positive: \n",
      "None\n",
      "200  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Ingredients: good ingredients\n",
      "Skin: sensitive skin\n",
      "201  Positive: \n",
      "Emotion: go to for years\n",
      "Skin: flaky skin.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "202  Positive: \n",
      "Value: worth the price\n",
      "Skin: baby skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "203  Positive: \n",
      "Emotion: forever be my go to\n",
      "Application: put it on at night\n",
      "\n",
      "Negative: \n",
      "None\n",
      "204  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Brand: shopping for a new moisturizer\n",
      "Ingredients: not as thick\n",
      "Skin: sensitive skin\n",
      "205  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Brand: go to moisturizer\n",
      "Application: use it for face & body\n",
      "206  Negative: \n",
      "Skin: my skin gets really dry\n",
      "\n",
      "Positive: \n",
      "None\n",
      "207  Positive: \n",
      "Ingredients: gentle ingredients\n",
      "Application: silky smooth\n",
      "\n",
      "Negative: \n",
      "None\n",
      "208  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: dry skin\n",
      "Partner: acne prone, red, dry, sensitive skin.\n",
      "209  Positive: \n",
      "Finish: face feeling soft\n",
      "\n",
      "Negative: \n",
      "None\n",
      "210  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: sensitive and irritated skin\n",
      "211  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: great purchase, great purchase\n",
      "Skin: body as well as face\n",
      "212  Positive: \n",
      "Emotion: very moisturizing\n",
      "\n",
      "Negative: \n",
      "None\n",
      "213  Positive: \n",
      "Emotion: love this moisturizer\n",
      "\n",
      "Negative: \n",
      "Texture: super thick and heavy\n",
      "214  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: $15 sale every Black Friday\n",
      "215  Negative: \n",
      "Application: it stings every time i rub it in\n",
      "Purchase: don’t think i’ll be purchasing it again\n",
      "Skin: doesn’t do a good job at moisturizing\n",
      "\n",
      "Positive: \n",
      "None\n",
      "216  Negative: \n",
      "Ingredients: ingredient change broke out\n",
      "Motivation: very expensive body moisturizer\n",
      "Skin: my skin instantly broke out\n",
      "\n",
      "Positive: \n",
      "None\n",
      "217  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: sensitive skin’s holy grail\n",
      "218  Positive: \n",
      "Value: great price point\n",
      "Skin: skin feel\n",
      "\n",
      "Negative: \n",
      "None\n",
      "219  Negative: \n",
      "Application: didn’t spread easily\n",
      "Skin: more hydration\n",
      "\n",
      "Positive: \n",
      "None\n",
      "220  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Finish: pills extensively\n",
      "221  Positive: \n",
      "Brand: Best cream\n",
      "\n",
      "Negative: \n",
      "None\n",
      "222  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Skin: feels more dryer, burns\n",
      "223  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: product to help sooth\n",
      "Application: didn't sting\n",
      "224  Positive: \n",
      "Time: absorbs pretty quickly\n",
      "\n",
      "Negative: \n",
      "None\n",
      "225  Positive: \n",
      "Emotion: best!\n",
      "Skin: red dry skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "226  Negative: \n",
      "Emotion: very displeased\n",
      "Purchase: won’t be repurchasing\n",
      "Ingredients: formula change\n",
      "\n",
      "Positive: \n",
      "None\n",
      "227  Positive: \n",
      "Emotion: game changer\n",
      "Value: super good price\n",
      "Skin: sensitive, dry, acne prone skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "228  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: hand cream\n",
      "Partner: fully healed them\n",
      "229  Positive: \n",
      "Emotion: love this product\n",
      "Purchase: like this more than the tube\n",
      "Skin: soft. my skin so soft\n",
      "\n",
      "Negative: \n",
      "None\n",
      "230  Negative: \n",
      "Application: it made it itchy\n",
      "Skin: my skin is extra sensitive\n",
      "\n",
      "Positive: \n",
      "None\n",
      "231  Positive: \n",
      "Purchase: always come back\n",
      "Application: put it on while your skin is still kind of damp\n",
      "Skin: dry skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "232  Positive: \n",
      "Value: value size\n",
      "\n",
      "Negative: \n",
      "Purchase: lost my package\n",
      "Availability: unavailable everywhere.\n",
      "233  Positive: \n",
      "Emotion: highly recommended\n",
      "Purchase: ordered this face cream again and again\n",
      "Skin: skin clearer\n",
      "\n",
      "Negative: \n",
      "None\n",
      "234  Positive: \n",
      "Purchase: love it!!!\n",
      "Skin: baby soft skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "235  Positive: \n",
      "Emotion: greatest\n",
      "Skin: sensitive skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "236  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: love this cream\n",
      "237  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: LOVE, LOVE, LOVE!\n",
      "Skin: works wonders\n",
      "238  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: container lasts forever\n",
      "Skin: hydrating my skin\n",
      "239  Positive: \n",
      "Emotion: sooooooo nice\n",
      "\n",
      "Negative: \n",
      "None\n",
      "240  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: not oily or greasy,\n",
      "Skin: my skin is suffering\n",
      "241  Negative: \n",
      "Value: not worth buying\n",
      "Skin: my skin start breaking out\n",
      "\n",
      "Positive: \n",
      "None\n",
      "242  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: instant hydration\n",
      "243  Positive: \n",
      "Ingredients: not itchiness\n",
      "Purchase: get the big size\n",
      "Skin: combo/oily dehydrated skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "244  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Purchase: not a good end result\n",
      "Skin: breakout\n",
      "245  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Application: hoping for a thicker texture\n",
      "246  Positive: \n",
      "Emotion: 10/10 recommend\n",
      "Skin: hypersensitive skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "247  Positive: \n",
      "Emotion: best!\n",
      "\n",
      "Negative: \n",
      "None\n",
      "248  Positive: \n",
      "Value: justified the price.\n",
      "Skin: leaves my skin happy.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "249  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Partner: Differin Adaplene gel\n",
      "Skin: skin look plump and healthy\n",
      "250  Negative: \n",
      "Ingredients: formula has changed in 2021\n",
      "Emotion: displeased\n",
      "\n",
      "Positive: \n",
      "None\n",
      "251  Positive: \n",
      "Ingredients: clean,\n",
      "Emotion: holy grail\n",
      "\n",
      "Negative: \n",
      "None\n",
      "252  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: OML am I glad\n",
      "Application: a little goes a long way\n",
      "Skin: my skin feels so hydrated\n",
      "253  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: first thicker cream\n",
      "Application: doesn’t burn\n",
      "Skin: skin moist\n",
      "254  Positive: \n",
      "Comparing: like first aid beauty much more\n",
      "Skin: combination skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "255  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: feels light\n",
      "Moisture: actually hold some moisture\n",
      "256  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: skin completely changed\n",
      "257  Negative: \n",
      "Finish: pilling\n",
      "\n",
      "Positive: \n",
      "None\n",
      "258  Positive: \n",
      "Emotion: absolutely love it\n",
      "\n",
      "Negative: \n",
      "None\n",
      "259  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Ingredients: changed the formula\n",
      "Competitor: bring back the old formula\n",
      "260  Positive: \n",
      "Value: so much product\n",
      "\n",
      "Negative: \n",
      "None\n",
      "261  Negative: \n",
      "Application: super drying,\n",
      "Value: wasn't worth the price\n",
      "\n",
      "Positive: \n",
      "None\n",
      "262  Negative: \n",
      "Motivation: went back to this moisturizer\n",
      "Emotion: more and more pimples\n",
      "\n",
      "Positive: \n",
      "None\n",
      "263  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: purchased so many\n",
      "Demographic: super dry skin\n",
      "264  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: absorbs quickly\n",
      "Skin: so hydrating\n",
      "265  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Motivation: bought on a whim\n",
      "Ingredients: eucalyptus\n",
      "266  Positive: \n",
      "Value: good price\n",
      "Absorbs: relatively quick\n",
      "\n",
      "Negative: \n",
      "None\n",
      "267  Positive: \n",
      "Emotion: best night cream\n",
      "\n",
      "Negative: \n",
      "None\n",
      "268  Positive: \n",
      "Value: great price\n",
      "\n",
      "Negative: \n",
      "Odor: eucalyptus smells stale\n",
      "269  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Value: worth the try\n",
      "Purchase: definitely be buying\n",
      "Skin: less flaky skin\n",
      "270  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Purchase: going to be my go to moisturizer\n",
      "Skin: dry skin\n",
      "271  Negative: \n",
      "Ingredients: eucalyptus\n",
      "\n",
      "Positive: \n",
      "None\n",
      "272  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: for sensitive skin\n",
      "273  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Application: amazing option to put on\n",
      "Skin: skin is going through issues\n",
      "274  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: face feeling very soft\n",
      "275  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Ingredients: ingredients list\n",
      "Skin: dry skin\n",
      "276  Negative: \n",
      "Skin: worst I’ve ever had, caused whiteheads\n",
      "\n",
      "Positive: \n",
      "None\n",
      "277  Negative: \n",
      "Design: packaging is terrible\n",
      "\n",
      "Positive: \n",
      "None\n",
      "278  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Skin: stings my skin\n",
      "279  Positive: \n",
      "Value: good amount of product for the price\n",
      "\n",
      "Negative: \n",
      "None\n",
      "280  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Odor: scents\n",
      "Ingredients: reformulated\n",
      "281  Positive: \n",
      "Emotion: WOW. Just, I don't know why I ever left this product.\n",
      "\n",
      "Negative: \n",
      "None\n",
      "282  Positive: \n",
      "Purchase: highly recommend\n",
      "Skin: parched, dry skin\n",
      "\n",
      "Negative: \n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283  Positive: \n",
      "Emotion: I love this moisturizer\n",
      "\n",
      "Negative: \n",
      "None\n",
      "284  Positive: \n",
      "Value: huge amount for the price\n",
      "Time: timeless\n",
      "\n",
      "Negative: \n",
      "None\n",
      "285  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Moisturizer: saved me\n",
      "Time: put it on at night\n",
      "286  Negative: \n",
      "Application: takes more effort than most of my body products to work into the skin and fully dissolve\n",
      "Value: pretty thick and takes more effort than most of my body products to work into the skin and fully dissolve, pretty expensive\n",
      "\n",
      "Positive: \n",
      "Ingredients: some really great ingredients in here that are genuinely good for skin health\n",
      "Skin: heal and soothe skin\n",
      "287  Negative: \n",
      "Ingredients: felt like it was just there\n",
      "Skin: burned\n",
      "\n",
      "Positive: \n",
      "None\n",
      "288  Positive: \n",
      "Emotion: so good!\n",
      "Skin: sensitive skin\n",
      "\n",
      "Negative: \n",
      "None\n",
      "289  Positive: \n",
      "Purchase: purchased my second tub!!\n",
      "Skin: plumpness\n",
      "\n",
      "Negative: \n",
      "None\n",
      "290  Negative: \n",
      "Motivation: heard so many good things\n",
      "Skin: my face gets irritated\n",
      "\n",
      "Positive: \n",
      "None\n",
      "291  Positive: \n",
      "Time: skin feeling so good!\n",
      "\n",
      "Negative: \n",
      "None\n",
      "292  Positive: \n",
      "Purchase: just BUY!!\n",
      "Skin: dry, flaky\n",
      "\n",
      "Negative: \n",
      "None\n",
      "293  Positive: \n",
      "Skin: drying out horribly\n",
      "\n",
      "Negative: \n",
      "None\n",
      "294  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: skin is loving this.\n",
      "295  Negative: \n",
      "Emotion: irritated\n",
      "\n",
      "Positive: \n",
      "None\n",
      "296  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: jaw drop\n",
      "Finish: skin the smoothest\n",
      "297  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Emotion: holy grail\n",
      "Time: lasts throughout the day\n",
      "298  Negative: \n",
      "None\n",
      "\n",
      "Positive: \n",
      "Skin: moisturizes my skin\n",
      "299  Positive: \n",
      "None\n",
      "\n",
      "Negative: \n",
      "Competitor: felt like that moisturized my skin better,\n"
     ]
    }
   ],
   "source": [
    "#Printing and Storing Completions in dataframe\n",
    "for i in range(len(df)):\n",
    "    prompt = df['prompt'][i]\n",
    "    response = openai.Completion.create(\n",
    "      model=\"davinci:ft-moksh-2023-01-11-15-14-35\",\n",
    "      prompt=prompt,\n",
    "      temperature=0.7,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      stop=[\"\\n END\"]\n",
    "    )\n",
    "    df['completion'][i] = response['choices'][0]['text']\n",
    "    print(i,df['completion'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86c26134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = process_completion(df)\n",
    "df = completion_to_phdf(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cd298",
   "metadata": {},
   "source": [
    "# completion processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f0ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Completion into 'Positive' & 'Negative' Sentiments\n",
    "def process_completion(df):\n",
    "    df['Negative']=''\n",
    "    df['Positive']=''\n",
    "\n",
    "    for i in df.index:\n",
    "        if type(df['completion'][i])==float:\n",
    "            continue\n",
    "        l1 = df['completion'][i].split('###')\n",
    "        if len(l1)>=2:\n",
    "            l = df['completion'][i].split('###')[1].split('\\n\\n')\n",
    "        else:\n",
    "            l = df['completion'][i].split('\\n\\n')\n",
    "        if(len(l)==1):\n",
    "    #         print(i,df['completion'][i],l)\n",
    "            continue\n",
    "        if l[0]=='':\n",
    "            l.pop(0)\n",
    "    #     if l[0][1]=='#':\n",
    "    #         l[0] = l[0][3:]\n",
    "        l[0] = l[0].strip()\n",
    "    #     print(i)\n",
    "        try:\n",
    "            if l[0][0].lower()=='n':\n",
    "                df['Negative'][i] = l[0]\n",
    "                df['Positive'][i] = l[1]\n",
    "            else:\n",
    "                df['Negative'][i] = l[1]\n",
    "                df['Positive'][i] = l[0]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df['Negative'] = df['Negative'].str.split('Negative: ',expand=True)[1]\n",
    "    df['Positive'] = df['Positive'].str.split('Positive: ',expand=True)[1]\n",
    "    df['Negative'] = df['Negative'].str.split('\\n')\n",
    "    df['Positive'] = df['Positive'].str.split('\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13ba9c",
   "metadata": {},
   "source": [
    "# completion -> phrase dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc5c1c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generating phrase dataframe from completions dataframe which contains 'Positive' & ' Negative' columns\n",
    "def completion_to_phdf(df): #'P1_Estee Lauder.csv'\n",
    "#     daf = pd.read_csv('P1_Estee Lauder.csv')\n",
    "#     df = pd.merge(df,daf.loc[:,['Review ID','Date','Rating']],on='Review ID')\n",
    "#     df.drop_duplicates(['Review ID'],inplace=True)\n",
    "#     df['Rating'] = df[\"Rating\"].apply(lambda x : int(x.split()[0]))\n",
    "#     df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    resultlist=[]\n",
    "    for i in df.index:\n",
    "        for senti in ['Positive','Negative']:\n",
    "            #'NaN' and 'None' values handling\n",
    "            if df[senti][i] is None or type(df[senti][i])==float:\n",
    "                continue\n",
    "            \n",
    "            #Case Handling\n",
    "            if type(df[senti][i])==list:\n",
    "                l = df[senti][i]\n",
    "            else:\n",
    "                l = ast.literal_eval(df[senti][i])\n",
    "                \n",
    "            for aspects in l:\n",
    "                aspect = aspects.split(':')[0]\n",
    "                try:\n",
    "                    phrases = aspects.split(':')[1]\n",
    "                except:\n",
    "                    continue\n",
    "                for phrase in phrases.split(','):\n",
    "                    result={}\n",
    "                    result['Review ID'] = df['Review ID'][i]\n",
    "                    result['Sentiment'] = senti\n",
    "                    result['Review'] = df['Review'][i]\n",
    "                    result['Rating'] = df['Rating'][i]\n",
    "                    result['Date'] = df['Date'][i]\n",
    "                    result['Phrase'] = phrase\n",
    "                    result['Aspect'] = aspect\n",
    "                    resultlist.append(result)\n",
    "    df3 = pd.DataFrame.from_dict(resultlist, orient='columns')\n",
    "    df3['Rating'] = df3[\"Rating\"].apply(lambda x : int(x.split()[0]))\n",
    "    df3['Date'] = pd.to_datetime(df3['Date'])\n",
    "    df3.drop_duplicates(inplace=True)\n",
    "    df3 = df3.sort_values(['Sentiment','Aspect'],ascending=False)\n",
    "    df3 = df3[df3['Phrase'].astype(bool)]\n",
    "    df3.index = range(len(df3))\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2f950",
   "metadata": {},
   "source": [
    "# Detailed Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59621e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard coded dictionaries are created to club L2 aspects together to form L1 Clusters\n",
    "dP4 = {'Performance':['Allergy','Performance','Skin'],\n",
    "         'Application':['Application','Texture'],\n",
    "        'Emotional':['Brand','Competitor','Purchase','Sentiment'],\n",
    "        'Product':['Demographic','Motivation','Odor','Packaging','Price']}\n",
    "\n",
    "dP1 = { 'Performance':['Skin','Performance'],\n",
    "       'Application':['Texture','Application'],\n",
    "       'Emotional':['Brand','Competitor','Purchase'],\n",
    "    'Product':['Value','Time','Partner','Odor','Motivation','Ingredients','Design',\n",
    "                  'Finish','Emotion','Demographic','Coverage','Color']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d098eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_creation(sheet5,layer):\n",
    "    for senti in ['Positive','Negative']:\n",
    "        a = sheet5[sheet5.Sentiment==senti]\n",
    "        L2 = {}\n",
    "        if layer=='L2':\n",
    "            x = 'L3'\n",
    "        else:\n",
    "            x = 'L2'\n",
    "        #Calculating the layer values (count,avg) using its next layer vales    \n",
    "        for aspect in a[layer+' Cluster'].unique():\n",
    "            b = a[a[layer+' Cluster']==aspect]\n",
    "            d = {}\n",
    "            for cluster in b[x+' Cluster'].unique():\n",
    "                c = b[b[x+' Cluster']==cluster]\n",
    "                pcount = list(b[b[x+' Cluster']==cluster][x+' Phrase Count'])[0]\n",
    "                rcnt = list(b[b[x+' Cluster']==cluster][x+' Review Count'])[0]\n",
    "                prating = list(b[b[x+' Cluster']==cluster][x+' Rating (Phrase)'])[0]\n",
    "                rrat = list(b[b[x+' Cluster']==cluster][x+' Rating (Review)'])[0]\n",
    "                d[cluster] = [pcount,prating,rcnt,rrat]\n",
    "            p_total = 0\n",
    "            p_product = 0\n",
    "            r_total = 0\n",
    "            r_product = 0\n",
    "            for key,value in d.items():\n",
    "                try:\n",
    "                    p_total+=value[0]\n",
    "                    r_total+=value[2]\n",
    "                except:\n",
    "                    continue\n",
    "                p_product+=(value[0]*value[1])\n",
    "                r_product+=(value[2]*value[3])\n",
    "            try:\n",
    "                L2[aspect] = [p_total,p_product/p_total,r_total,r_product/r_total]\n",
    "            except:\n",
    "                continue\n",
    "        #Inserting them into sheet5\n",
    "        for aspect,value in L2.items():\n",
    "            for i in sheet5[(sheet5.Sentiment==senti) & (sheet5[layer+' Cluster']==aspect)].index:\n",
    "                sheet5[layer+' Phrase Count'][i] = value[0]\n",
    "                sheet5[layer+' Rating (Phrase)'][i] = value[1]\n",
    "                sheet5[layer+' Review Count'][i] = value[2]\n",
    "                sheet5[layer+' Rating (Review)'][i] = value[3]\n",
    "    print(layer+\" Completed\\n\")\n",
    "    return sheet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d9c6014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detailed_output(df,map_dict,client,take_sentiment=True,flag_rating=4,compress=True,words_per_topic=5,ng_range=(1,3),\n",
    "                    words_to_remove=[],date=date.today().strftime('%Y%m%d'),version='v1',create_exl=False):\n",
    "    df3=df\n",
    "    #########################################sheet5##########################################\n",
    "    sheet5 = pd.DataFrame(columns=['Sentiment','L1 Cluster ID','L1 Cluster','L1 Phrase Count','L1 Review Count',\n",
    "                                   'L1 Rating (Phrase)','L1 Rating (Review)','L2 Cluster ID','L2 Cluster','L2 Phrase Count',\n",
    "                                   'L2 Review Count','L2 Rating (Phrase)','L2 Rating (Review)','L3 Cluster ID','L3 Cluster',\n",
    "                                   'L3 Cluster Phrase','L3 Phrase Count','L3 Review Count','L3 Rating (Review)',\n",
    "                                   'L3 Rating (Phrase)','L4 ID','L4 Phrase','Review ID','Review Rating'])\n",
    "    sheet5['Sentiment'] = df3.Sentiment\n",
    "    sheet5['L2 Cluster'] = df3.Aspect\n",
    "    sheet5['L4 Phrase'] = df3.Phrase\n",
    "    sheet5['Review'] = df3.Review\n",
    "    sheet5['Review ID'] = df3['Review ID']\n",
    "    sheet5['Review Rating'] = df3.Rating\n",
    "    sheet5['Date'] = pd.to_datetime(df3.Date)\n",
    "#     sheet5 = sheet5.merge(daf.loc[:,['Review ID','Verified Purchase', 'Recommended',\n",
    "#            'Incentivized', 'Upvote', 'Downvote', 'AgeRange', 'SkinConcerns']],on='Review ID')\n",
    "    sheet5.fillna('',inplace=True)\n",
    "    print(\"Clustering Started\\n\")\n",
    "    \n",
    "    #######################################Clustering###########################################\n",
    "    print(\"BERTopic Clustering will take a while\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your',\n",
    "     'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", \n",
    "    'its','itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", \n",
    "    'these','those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "    'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', \n",
    "    'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how',\n",
    "    'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too',\n",
    "    'very', 's', 't','can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', \n",
    "    'ain', 'aren', \"aren't\",'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven',\n",
    "     \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \n",
    "     \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'since','first', 'even',\n",
    "     'thisssss', 'could','really','always','bc','truly','literally','48','none','yet','actually','like','would','ever','issss',\n",
    "    'although','much','10','do','super','c','f','definitely','completely','totally','ski','ive','not']+words_to_remove # 'not','no'\n",
    "    def tokenization(text):\n",
    "        tk = WhitespaceTokenizer()\n",
    "        return tk.tokenize(text)\n",
    "    def remove_stopwords(text):\n",
    "        output= [i for i in text if i.lower() not in stopwords]\n",
    "        return output\n",
    "\n",
    "    df3.dropna(inplace=True)\n",
    "#     v = CountVectorizer(ngram_range = ng_range,stop_words=\"english\")\n",
    "#     vd = v.fit_transform(list(df3.loc[:, \"Phrase\"].values))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #Doing clustering for every aspect in every sentiment\n",
    "    for senti in ['Positive','Negative']:\n",
    "        for aspect in df3.Aspect.unique():\n",
    "            if take_sentiment:\n",
    "                df1 = df3[(df3.Aspect==aspect)&(df3.Sentiment==senti)]\n",
    "                print('Sentiment:',senti,'Aspect:',aspect)\n",
    "            else:\n",
    "                df1 = df3[(df3.Aspect==aspect)]\n",
    "                print('Aspect:',aspect)\n",
    "            df1 = df1.reset_index()\n",
    "            if len(df1)==0:\n",
    "                print(\"There are no phrases for this aspect & sentiment.\")\n",
    "                continue\n",
    "\n",
    "            docs = list(df1.loc[:, \"Phrase\"].values)\n",
    "\n",
    "            # Lemmatization\n",
    "            for i in range(len(docs)):\n",
    "                doc = nlp(docs[i])\n",
    "                tokens = []\n",
    "                for token in doc:\n",
    "                    tokens.append(token)\n",
    "                lemmatized_sentence = \" \".join([token.lemma_ for token in doc])\n",
    "                docs[i] = lemmatized_sentence\n",
    "\n",
    "            docs = pd.Series(docs).apply(lambda x: tokenization(x)) #Tokenization is done to remove stopwords\n",
    "            docs = docs.apply(lambda x:remove_stopwords(x))\n",
    "            for i in range(len(docs)):\n",
    "                docs[i] = \" \".join(docs[i])\n",
    "            \n",
    "            #This code is used to only retain adverb, verb, adjective, noun, pronoun & 'X' part of speech words\n",
    "            #For more information about part of speech refer spacy website\n",
    "            lst = ['ADV','VERB','ADJ','NOUN','PROPN','X']\n",
    "\n",
    "            for i in range(len(docs)):\n",
    "                sent = nlp(docs[i])\n",
    "                text= []\n",
    "                for word in sent:\n",
    "                    if not word.is_punct and word.pos_ in lst:#not word.is_stop and\n",
    "                        text.append(word.lemma_) #ps.stem(word.lemma_)\n",
    "                \n",
    "                #This code is used to convert some word into another. This is useful in Topic Modelling\n",
    "                suffix = {'hydrating':'hydrate','hydrated':'hydrate','hydration':'hydrate'}\n",
    "                for j in range(len(text)):\n",
    "                    for su,w in suffix.items():\n",
    "                        if text[j].endswith(su):\n",
    "                            text[j] = text[j][:-len(su)] + w\n",
    "                \n",
    "                #This code is used to remove duplicate words from phrases\n",
    "                k = []\n",
    "                st = ' '.join(text)\n",
    "                for x in text:\n",
    "                    if (st.count(x)>=1 and (x not in k)):\n",
    "                        k.append(x)\n",
    "#                 k.sort()\n",
    "                docs[i] = ' '.join(k)\n",
    "\n",
    "            docs = pd.Series(docs)\n",
    "\n",
    "            #Removing empty phrases from docs [Those phrases which contains stopwords]\n",
    "            df1['cp'] = docs\n",
    "            df1 = df1[df1.cp.astype(bool)]\n",
    "            docs = docs[docs.astype(bool)]\n",
    "            df1.index=range(len(df1))\n",
    "            docs.index=range(len(docs))\n",
    "            \n",
    "            #To enable compression while Topic Modelling\n",
    "            if compress:\n",
    "                compress=\"auto\"\n",
    "            else:\n",
    "                compress=None\n",
    "                \n",
    "            try:\n",
    "                modal = BERTopic(top_n_words = words_per_topic,\n",
    "                             calculate_probabilities = True,  #Used in Outlier Reduction\n",
    "                             vectorizer_model = TfidfVectorizer(  #This vectorizer takes the importance of a word or ngram into consideration using tfidf\n",
    "#                                              vocabulary = v.get_feature_names_out(),\n",
    "                                             ngram_range = ng_range,\n",
    "                                             stop_words=\"english\"),\n",
    "                             nr_topics=compress,\n",
    "                             diversity=1, #To diversify the generated topics. Set to maximum\n",
    "                             umap_model=UMAP(random_state=2), #Dimensionality Reduction Model, random_state is defined to make BERTopic reproducible\n",
    "                             ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True,bm25_weighting=True), #Used for topic compression\n",
    "                             language=\"english\",\n",
    "                             n_gram_range=ng_range) \n",
    "                topics, probs = modal.fit_transform(docs.values)\n",
    "                \n",
    "                try:\n",
    "                    #Reducing Outliers [Removing the -1 topic and Making Cleaner Topics as well]\n",
    "                    topics = modal.reduce_outliers(docs.values, topics, probabilities=probs, strategy=\"probabilities\")\n",
    "                    modal.update_topics(docs.values, topics=topics)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                #Storing clusters corresponding to each phrase in df1\n",
    "                df1['Cluster']=''\n",
    "#                     predicted_topics, predicted_probs = modal.transform(docs)\n",
    "                #This code is used to remove duplicate words inside a topic name\n",
    "                for i in range(len(df1)):\n",
    "                    s = modal.get_topic(topics[i])[0][0]\n",
    "                    l = s.split()\n",
    "                    k = []\n",
    "                    for x in l:\n",
    "                        if (s.count(x)>=1 and (x not in k)):\n",
    "                            k.append(x)\n",
    "                    df1['Cluster'][i] = ' '.join(k)\n",
    "                    \n",
    "                print(modal.get_topic_info())\n",
    "                print(pd.DataFrame(df1['Cluster'].value_counts()))\n",
    "            except Exception as e:\n",
    "                print('Aspect contains insufficient number of phrases for clustering. BERTopic Error.\\n')\n",
    "                print(e)\n",
    "                df1['Cluster']=aspect\n",
    "            \n",
    "            #This code will give us the most similar phrase inside each L3 Cluster\n",
    "            df1['L3 Cluster Phrase']=''\n",
    "            df1['sim'] = ''\n",
    "            df1.drop(['index'],1,inplace=True)\n",
    "            if len(df1)==1:\n",
    "                df1['L3 Cluster Phrase'] = df1['Phrase'].iloc[0]\n",
    "            else:\n",
    "    #Calculating the mean similarity score corresponding to each phrase & then taking the phrase with max mean similarity score\n",
    "                for cluster in df1['Cluster'].unique():\n",
    "                    for i in df1[df1.Cluster==cluster].index:\n",
    "                        sim=[]\n",
    "                        for j in df1[df1.Cluster==cluster].index:\n",
    "                            if i!=j:\n",
    "                                sim.append(jellyfish.levenshtein_distance(df1['Phrase'][i],df1['Phrase'][j]))\n",
    "                        df1['sim'][i] = sum(sim)/len(sim)\n",
    "                        \n",
    "                    m = df1[df1.Cluster==cluster]['sim'].min()\n",
    "                    p = list(df1[(df1.Cluster==cluster)&(df1['sim']==m)]['Phrase'])[0]\n",
    "                    for i in df1[df1.Cluster==cluster].index:\n",
    "                        df1['L3 Cluster Phrase'][i] = p\n",
    "            print(df1.loc[:,['Cluster','L3 Cluster Phrase']].drop_duplicates(),'\\n')\n",
    "            print(df1)\n",
    "            #This code will generate the summary of L3 Clusters and store it in sheet5\n",
    "            cluster_count = {}\n",
    "            for review in df1.Review.unique():\n",
    "                for cluster in df1[df1.Review==review]['Cluster'].unique():\n",
    "                    try:\n",
    "                        cluster_count[cluster]+=1\n",
    "                    except:\n",
    "                        cluster_count[cluster]=1\n",
    "            x = pd.DataFrame(df1.groupby(['Cluster']).count()['Phrase'])\n",
    "            x.columns = ['L3 Phrase Count']\n",
    "            y = pd.DataFrame(cluster_count.values(),index=cluster_count.keys(),columns=['L3 Review Count'])\n",
    "            z = pd.DataFrame(df1.groupby('Cluster').mean()['Rating'])\n",
    "            z.columns = ['L3 Rating (Phrase)']\n",
    "            a = pd.DataFrame(df1.groupby(['Cluster','Review']).mean().groupby('Cluster').mean()['Rating'])\n",
    "            a.columns = ['L3 Rating (Review)']\n",
    "            layer3 = x.join(y).join(z).join(a)\n",
    "            layer3['Cluster'] = layer3.index\n",
    "            layer3.index = range(len(layer3))\n",
    "#             print(layer3)\n",
    "            if take_sentiment:\n",
    "                s = sheet5[(sheet5['L2 Cluster']==aspect)&(s.Sentiment==senti)]\n",
    "            else:\n",
    "                s = sheet5[(sheet5['L2 Cluster']==aspect)]\n",
    "                \n",
    "            for i in s.index:\n",
    "                try:\n",
    "                    c = list(df1[df1.Phrase==sheet5['L4 Phrase'][i]]['Cluster'])[0]\n",
    "                    sheet5['L3 Cluster'][i] = list(layer3[layer3.Cluster==c]['Cluster'])[0]\n",
    "                    sheet5['L3 Cluster Phrase'][i] = list(df1[df1.Phrase==sheet5['L4 Phrase'][i]]['L3 Cluster Phrase'])[0]\n",
    "                    sheet5['L3 Phrase Count'][i] = list(layer3[layer3.Cluster==c]['L3 Phrase Count'])[0]\n",
    "                    sheet5['L3 Review Count'][i] = list(layer3[layer3.Cluster==c]['L3 Review Count'])[0]\n",
    "                    sheet5['L3 Rating (Phrase)'][i] = list(layer3[layer3.Cluster==c]['L3 Rating (Phrase)'])[0]\n",
    "                    sheet5['L3 Rating (Review)'][i] = list(layer3[layer3.Cluster==c]['L3 Rating (Review)'])[0]\n",
    "                except Exception as e:\n",
    "#                     print(c,e)\n",
    "                    pass\n",
    "\n",
    "        if ~take_sentiment:\n",
    "            break\n",
    "    print(\"Clustering done after {:.2f} sec \\n\".format(time.time() - start_time))\n",
    "#     print(sheet5)\n",
    "    sheet5 = sheet5[sheet5['L3 Cluster'].astype(bool)] #To remove empty L3 clusters from sheet5\n",
    "    ###############################Layer 2 & 1 Creation##############################################\n",
    "    sheet5 = layer_creation(sheet5,'L2')\n",
    "    \n",
    "    #This code is used to map L2 Clusters to L1 Clusters\n",
    "    d = map_dict\n",
    "    for i in sheet5.index:\n",
    "        l1 = ''\n",
    "        for key,values in d.items():\n",
    "            if sheet5['L2 Cluster'][i] in values:\n",
    "                l1 = key\n",
    "                break\n",
    "        sheet5['L1 Cluster'][i] = key\n",
    "        \n",
    "    sheet5 = layer_creation(sheet5,'L1')\n",
    "    \n",
    "    ###################################Id insertion & output excel formation################################\n",
    "    id = 1\n",
    "    for u_phrase in sheet5['L4 Phrase'].unique():\n",
    "        for i in sheet5[sheet5['L4 Phrase']==u_phrase].index:\n",
    "            sheet5['L4 ID'][i] = client+'L4I'+ str(id)\n",
    "        id+=1\n",
    "    #Assigning different ids to the L3 Clusters inside L2 Clusters\n",
    "    id = 1\n",
    "    for ul2_cluster in sheet5['L2 Cluster'].unique():\n",
    "        for ul3_cluster in sheet5[sheet5['L2 Cluster']==ul2_cluster]['L3 Cluster'].unique():\n",
    "            for i in sheet5[(sheet5['L2 Cluster']==ul2_cluster) & (sheet5['L3 Cluster']==ul3_cluster)].index:\n",
    "                sheet5['L3 Cluster ID'][i] = client+'L3I'+ str(id)\n",
    "            id+=1\n",
    "\n",
    "    id = 1\n",
    "    for u_cluster in sheet5['L2 Cluster'].unique():\n",
    "        for i in sheet5[sheet5['L2 Cluster']==u_cluster].index:\n",
    "            sheet5['L2 Cluster ID'][i] = client+'L2I'+ str(id)\n",
    "        id+=1\n",
    "\n",
    "    id = 1\n",
    "    for u_cluster in sheet5['L1 Cluster'].unique():\n",
    "        for i in sheet5[sheet5['L1 Cluster']==u_cluster].index:\n",
    "            sheet5['L1 Cluster ID'][i] = client+'L1I'+ str(id)\n",
    "        id+=1\n",
    "    \n",
    "    #Creating different tabs in detailed output from sheet5 [layer 4]\n",
    "    d1 = sheet5\n",
    "    d2 = sheet5.iloc[:,:20]\n",
    "    d3 = sheet5.iloc[:,:13]\n",
    "    d4 = sheet5.iloc[:,:7]\n",
    "    #Sorting values\n",
    "    d1 = d1.sort_values(['L1 Cluster','L2 Cluster','Sentiment','L3 Phrase Count','L3 Cluster'],ascending=False)\n",
    "    d2 = d2.sort_values(['L1 Cluster','L2 Cluster','Sentiment','L3 Phrase Count','L3 Cluster'],ascending=False)\n",
    "    d3 = d3.sort_values(['L1 Cluster','Sentiment','L2 Phrase Count','L2 Cluster'],ascending=False)\n",
    "    d4 = d4.sort_values(['L1 Cluster','Sentiment'],ascending=False)\n",
    "    #Removing Duplicates\n",
    "    d2.drop_duplicates(['Sentiment','L2 Cluster','L3 Cluster'],inplace=True)\n",
    "    d3.drop_duplicates(['Sentiment','L2 Cluster'],inplace=True)\n",
    "    d4.drop_duplicates(['Sentiment','L1 Cluster'],inplace=True)\n",
    "    \n",
    "    #Flagging [used to determine wishlist etc.]\n",
    "    for x in [d1,d2]:\n",
    "        x['Flag']=''\n",
    "        for i in x.index:\n",
    "            if x['L3 Rating (Review)'][i]>=flag_rating:\n",
    "                x['Flag'][i] = x['Sentiment'][i][0]+'+'\n",
    "            else:\n",
    "                x['Flag'][i] = x['Sentiment'][i][0]+'-'\n",
    "        \n",
    "    #Creating output excel file\n",
    "    if create_exl:\n",
    "        name = client+\"_detailed_\"+date+version+\".xlsx\"\n",
    "        path = r\"{fname}\".format(fname=name)\n",
    "        with pd.ExcelWriter(path) as engine:\n",
    "            d1.to_excel(excel_writer=engine,sheet_name='L4',index=False)\n",
    "            d2.to_excel(excel_writer=engine,sheet_name='L3',index=False)\n",
    "            d3.to_excel(excel_writer=engine,sheet_name='L2',index=False)\n",
    "            d4.to_excel(excel_writer=engine,sheet_name='L1',index=False)\n",
    "        print(\"Excel File with 4 sheets is created.\\n\")\n",
    "        print(\"File name:\",name)\n",
    "    dfs = [d1,d2,d3,d4]\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f581868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('P4_combined_df_20230105.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f767aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Started\n",
      "\n",
      "BERTopic Clustering will take a while\n",
      "Aspect: Ingredients\n",
      "   Topic  Count                                               Name\n",
      "0      0     62                  0_ingredient_formula_clean_change\n",
      "1      1     20     1_eucalyptus_oil_eucalyptus oil_oil eucalyptus\n",
      "2      2     16  2_colloidal_colloidal oatmeal_oatmeal_colloida...\n",
      "            Cluster\n",
      "ingredient       62\n",
      "eucalyptus       20\n",
      "colloidal        16\n",
      "      Cluster    L3 Cluster Phrase\n",
      "0  ingredient  ove the ingredients\n",
      "1  eucalyptus      eucalyptus oil.\n",
      "2   colloidal    colloidal oatmeal \n",
      "\n",
      "   Review ID                                             Review       Aspect  \\\n",
      "0       P4R1  Disastrous formula change.\\n\\nI've been using ...  Ingredients   \n",
      "1       P4R1  Disastrous formula change.\\n\\nI've been using ...  Ingredients   \n",
      "2      P4R28  ABSOLUTE NO!!\\n\\nThis cream is very lightweigh...  Ingredients   \n",
      "3      P4R28  ABSOLUTE NO!!\\n\\nThis cream is very lightweigh...  Ingredients   \n",
      "4      P4R39  makes me breakout\\n\\nA little about my skin:\\n...  Ingredients   \n",
      "..       ...                                                ...          ...   \n",
      "93   P4R1183  I have used this product for a very long time ...  Ingredients   \n",
      "94   P4R1228  Feels very soft and creamy, definitely hydrate...  Ingredients   \n",
      "95   P4R1239  This moisturizer has really calmed down and mo...  Ingredients   \n",
      "96   P4R1280  I live for this stuff, especially in the winte...  Ingredients   \n",
      "97   P4R1368  The product is very thick. Scent is alright. B...  Ingredients   \n",
      "\n",
      "   Sentiment                                             Phrase        Date  \\\n",
      "0   Negative                          Disastrous formula change  2022-11-18   \n",
      "1   Negative                                         eucalyptus  2022-11-18   \n",
      "2   Positive                        oat, ceramides, niacinamide  2022-08-31   \n",
      "3   Negative                       clearly due to the silicones  2022-08-31   \n",
      "4   Positive                                            aha/bha  2022-07-31   \n",
      "..       ...                                                ...         ...   \n",
      "93  Negative                                    eucalyptus oil.  2019-03-04   \n",
      "94  Negative  eucalyptus oil that contributes to the aroma i...  2019-02-12   \n",
      "95  Positive       Thank you minimal and effective ingredients!  2019-02-04   \n",
      "96  Positive                                  Great clean smell  2019-01-11   \n",
      "97  Negative                         ingredients are very heavy  2018-11-24   \n",
      "\n",
      "    Rating                                              cp     Cluster  \\\n",
      "0        1                       disastrous formula change  ingredient   \n",
      "1        1                                      eucalyptus  eucalyptus   \n",
      "2        5                        oat ceramide niacinamide   colloidal   \n",
      "3        5                            clearly due silicone  ingredient   \n",
      "4        5                                             bha  ingredient   \n",
      "..     ...                                             ...         ...   \n",
      "93       4                                  eucalyptus oil  eucalyptus   \n",
      "94       4  eucalyptus oil contribute aroma make face burn  eucalyptus   \n",
      "95       5              thank minimal effective ingredient  ingredient   \n",
      "96       5                               great clean smell  ingredient   \n",
      "97       3                                ingredient heavy  ingredient   \n",
      "\n",
      "      L3 Cluster Phrase        sim  \n",
      "0   ove the ingredients  24.278689  \n",
      "1       eucalyptus oil.  21.789474  \n",
      "2     colloidal oatmeal  24.266667  \n",
      "3   ove the ingredients  24.180328  \n",
      "4   ove the ingredients  24.540984  \n",
      "..                  ...        ...  \n",
      "93      eucalyptus oil.  19.578947  \n",
      "94      eucalyptus oil.  53.842105  \n",
      "95  ove the ingredients  33.377049  \n",
      "96  ove the ingredients  21.721311  \n",
      "97  ove the ingredients  23.065574  \n",
      "\n",
      "[98 rows x 11 columns]\n",
      "Aspect: Brand\n",
      "   Topic  Count                                         Name\n",
      "0      0     37              0_fab_product_cream_fab product\n",
      "1      1     23                1_aid_beauty_aid beauty_thank\n",
      "2      2     19  2_brand_brand brand_vegan_brand brand vegan\n",
      "       Cluster\n",
      "fab         37\n",
      "aid         23\n",
      "brand       19\n",
      "   Cluster        L3 Cluster Phrase\n",
      "0      fab      fan of FAB products\n",
      "5      aid  Thanks First Aid Beauty\n",
      "11   brand    discovered this brand \n",
      "\n",
      "   Review ID                                             Review Aspect  \\\n",
      "0       P4R1  Disastrous formula change.\\n\\nI've been using ...  Brand   \n",
      "1      P4R37  A cult classic you should try\\n\\nIt’s only my ...  Brand   \n",
      "2      P4R46  my holy grail\\n\\nI have to say, I love FAB pro...  Brand   \n",
      "3      P4R63  Hate this\\n\\nThis is the worst cream I have ev...  Brand   \n",
      "4      P4R63  Hate this\\n\\nThis is the worst cream I have ev...  Brand   \n",
      "..       ...                                                ...    ...   \n",
      "74   P4R1220  I am absolutely in LOVE with this moisturizer....  Brand   \n",
      "75   P4R1231  This works soooo well. My chin area was peelin...  Brand   \n",
      "76   P4R1281  Love FaB beauty products. With severe psoriasi...  Brand   \n",
      "77   P4R1299  This is a really great moisturizer - especiall...  Brand   \n",
      "78   P4R1302  This product has a very strong herbal/medicina...  Brand   \n",
      "\n",
      "   Sentiment                             Phrase        Date  Rating  \\\n",
      "0   Negative               using this FAB cream  2022-11-18       1   \n",
      "1   Positive  love the whole concept behind FAB  2022-08-09       5   \n",
      "2   Positive                I love FAB products  2022-07-19       5   \n",
      "3   Positive                             Kiehls  2022-06-15       2   \n",
      "4   Positive                           Clinique  2022-06-15       2   \n",
      "..       ...                                ...         ...     ...   \n",
      "74  Positive          my new go to moisturizer.  2019-02-12       5   \n",
      "75  Positive    First Aid Beauty works wonders.  2019-02-10       5   \n",
      "76  Positive          Love FaB beauty products.  2019-01-11       5   \n",
      "77  Positive                fan of FAB products  2019-01-08       5   \n",
      "78  Negative         nds me A LOT of the Cerave  2019-01-07       3   \n",
      "\n",
      "                         cp Cluster        L3 Cluster Phrase        sim  \n",
      "0             use FAB cream     fab      fan of FAB products  23.888889  \n",
      "1    love whole concept FAB     fab      fan of FAB products  29.972222  \n",
      "2          love FAB product     fab      fan of FAB products  23.972222  \n",
      "3                    Kiehls     fab      fan of FAB products  26.583333  \n",
      "4                  Clinique     fab      fan of FAB products  26.138889  \n",
      "..                      ...     ...                      ...        ...  \n",
      "74       new go moisturizer     fab      fan of FAB products  25.861111  \n",
      "75   aid beauty work wonder     aid  Thanks First Aid Beauty  24.636364  \n",
      "76  love FaB beauty product     fab      fan of FAB products  25.666667  \n",
      "77          fan FAB product     fab      fan of FAB products  23.833333  \n",
      "78            nd LOT cerave   brand    discovered this brand  27.944444  \n",
      "\n",
      "[79 rows x 11 columns]\n",
      "Aspect: Purchase\n",
      "   Topic  Count                                               Name\n",
      "0      0     84                           0_buy_size_year_purchase\n",
      "1      1     45           1_purchase_buy_purchase purchase_buy buy\n",
      "2      2     27  2_repurchase_repurchase repurchase_repurchase ...\n",
      "            Cluster\n",
      "buy              84\n",
      "purchase         45\n",
      "repurchase       27\n",
      "      Cluster   L3 Cluster Phrase\n",
      "0         buy  buy the large tube\n",
      "2  repurchase     will repurchase\n",
      "3    purchase    not buy it again \n",
      "\n",
      "    Review ID                                             Review    Aspect  \\\n",
      "0        P4R1  Disastrous formula change.\\n\\nI've been using ...  Purchase   \n",
      "1        P4R4  Used to be great product 3+ years ago, not any...  Purchase   \n",
      "2       P4R10  A must have!\\n\\nThis is the perfect moisturize...  Purchase   \n",
      "3       P4R11  A MUST HAVE\\n\\nHOLY GRAIL! \\n\\nI use this on e...  Purchase   \n",
      "4       P4R23  Not The Best\\n\\nI was not impressed with this....  Purchase   \n",
      "..        ...                                                ...       ...   \n",
      "151   P4R1330  This seems to work as a body cream for me, but...  Purchase   \n",
      "152   P4R1334  One of my favorite lotions. Lightweight. Neutr...  Purchase   \n",
      "153   P4R1341  I always thought I had oily skin because my fa...  Purchase   \n",
      "154   P4R1351  The FAB Ultra Repair Cream is EVERYTHING! For ...  Purchase   \n",
      "155   P4R1373  Got this as a sample with one of my previous p...  Purchase   \n",
      "\n",
      "    Sentiment                              Phrase        Date  Rating  \\\n",
      "0    Positive                     almost a decade  2022-11-18       1   \n",
      "1    Positive            every year for Christmas  2022-10-31       2   \n",
      "2    Positive            repurchased serval times  2022-10-07       3   \n",
      "3    Positive           even give it out as gifts  2022-10-05       5   \n",
      "4    Negative          not be purchasing it again  2022-09-14       5   \n",
      "..        ...                                 ...         ...     ...   \n",
      "151  Negative  would probably not purchase again.  2018-12-18       4   \n",
      "152  Positive               I'd snap it up quick.  2018-12-17       5   \n",
      "153  Positive                          3rd order.  2018-12-17       5   \n",
      "154  Positive               more than 6x already!  2018-12-12       5   \n",
      "155  Positive                          full size.  2018-11-22       5   \n",
      "\n",
      "                         cp     Cluster   L3 Cluster Phrase        sim  \n",
      "0             almost decade         buy  buy the large tube  24.036145  \n",
      "1            year Christmas         buy  buy the large tube  25.481928  \n",
      "2    repurchase serval time  repurchase     will repurchase  20.961538  \n",
      "3                 give gift    purchase    not buy it again  21.181818  \n",
      "4                  purchase    purchase    not buy it again  19.295455  \n",
      "..                      ...         ...                 ...        ...  \n",
      "151       probably purchase    purchase    not buy it again  23.954545  \n",
      "152              snap quick    purchase    not buy it again  21.295455  \n",
      "153               3rd order         buy  buy the large tube  25.180723  \n",
      "154              6x already         buy  buy the large tube  24.445783  \n",
      "155               full size         buy  buy the large tube  24.795181  \n",
      "\n",
      "[156 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Demographic\n",
      "   Topic  Count                                               Name\n",
      "0      0     74                        0_old_year_year old_husband\n",
      "1      1     63                        1_dry_live_dry winter_cream\n",
      "2      2     32  2_winter_winter winter_especially winter winte...\n",
      "3      3     19  3_month_winter month_month winter_month winter...\n",
      "4      4     14             4_cold_weather_winter cold_cold winter\n",
      "        Cluster\n",
      "old          74\n",
      "dry          63\n",
      "winter       32\n",
      "month        19\n",
      "cold         14\n",
      "   Cluster    L3 Cluster Phrase\n",
      "0     cold  cold winter weather\n",
      "1      old        my 7 year old\n",
      "2   winter        in the winter\n",
      "8      dry       very dry state\n",
      "21   month        winter months \n",
      "\n",
      "    Review ID                                             Review       Aspect  \\\n",
      "0        P4R1  Disastrous formula change.\\n\\nI've been using ...  Demographic   \n",
      "1        P4R2  Best by far\\n\\nI got this while it was on sale...  Demographic   \n",
      "2        P4R2  Best by far\\n\\nI got this while it was on sale...  Demographic   \n",
      "3        P4R4  Used to be great product 3+ years ago, not any...  Demographic   \n",
      "4        P4R8  A must have in winter holy grail and saver\\n\\n...  Demographic   \n",
      "..        ...                                                ...          ...   \n",
      "197   P4R1349  Great product for winter. Where I live get rea...  Demographic   \n",
      "198   P4R1353  Would give this cream 10 stars if I could. Per...  Demographic   \n",
      "199   P4R1355  As someone with dehydrated skin living in New ...  Demographic   \n",
      "200   P4R1373  Got this as a sample with one of my previous p...  Demographic   \n",
      "201   P4R1374  I bought this for my mom cuz she want somethin...  Demographic   \n",
      "\n",
      "    Sentiment                     Phrase        Date  Rating  \\\n",
      "0    Positive         very harsh winters  2022-11-18       1   \n",
      "1    Positive        work in health care  2022-11-18       5   \n",
      "2    Positive                     winter  2022-11-18       5   \n",
      "3    Positive  especially during winter,  2022-10-31       2   \n",
      "4    Positive           winter holy grai  2022-10-21       5   \n",
      "..        ...                        ...         ...     ...   \n",
      "197  Positive       winter. Where I live  2018-12-14       5   \n",
      "198  Positive          14 weeks pregnant  2018-12-10       5   \n",
      "199  Positive             winter months,  2018-12-04       5   \n",
      "200  Positive     searching for a winter  2018-11-22       5   \n",
      "201  Positive             my mom cuz she  2018-11-20       4   \n",
      "\n",
      "                    cp Cluster    L3 Cluster Phrase        sim  \n",
      "0         harsh winter    cold  cold winter weather  15.692308  \n",
      "1     work health care     old        my 7 year old   18.09589  \n",
      "2               winter  winter        in the winter  12.677419  \n",
      "3    especially winter  winter        in the winter  17.967742  \n",
      "4     winter holy grai  winter        in the winter  14.967742  \n",
      "..                 ...     ...                  ...        ...  \n",
      "197        winter live  winter        in the winter  16.580645  \n",
      "198      week pregnant     old        my 7 year old  17.575342  \n",
      "199       winter month   month        winter months   7.444444  \n",
      "200      search winter  winter        in the winter   16.16129  \n",
      "201                mom     old        my 7 year old  16.068493  \n",
      "\n",
      "[202 rows x 11 columns]\n",
      "Aspect: Sentiment\n",
      "   Topic  Count                                               Name\n",
      "0      0    140                          0_product_love_stuff_hype\n",
      "1      1     71                            1_cream_face_skin_ultra\n",
      "2      2     34            2_holy_holy grail_grail_holy grail holy\n",
      "3      3     23  3_moisturizer_love moisturizer_good moisturize...\n",
      "4      4     21  4_recommend_recommend recommend_recommend reco...\n",
      "5      5     14  5_highly_highly recommend_recommend highly_rec...\n",
      "             Cluster\n",
      "product          140\n",
      "cream             71\n",
      "holy              34\n",
      "moisturizer       23\n",
      "recommend         21\n",
      "highly            14\n",
      "        Cluster      L3 Cluster Phrase\n",
      "0         cream     Ultra Repair cream\n",
      "4        highly       highly recommend\n",
      "5       product      Love this product\n",
      "7   moisturizer  love this moisturizer\n",
      "22         holy             holy grail\n",
      "25    recommend        Don’t recommend \n",
      "\n",
      "    Review ID                                             Review     Aspect  \\\n",
      "0        P4R1  Disastrous formula change.\\n\\nI've been using ...  Sentiment   \n",
      "1        P4R6  Worth it! Calms rosacea\\n\\nI have rosacea and ...  Sentiment   \n",
      "2       P4R10  A must have!\\n\\nThis is the perfect moisturize...  Sentiment   \n",
      "3       P4R17  Instant Hydration\\n\\nStarting using this Ultra...  Sentiment   \n",
      "4       P4R17  Instant Hydration\\n\\nStarting using this Ultra...  Sentiment   \n",
      "..        ...                                                ...        ...   \n",
      "298   P4R1338  AMAZING for really dry skin !! Itâ€™s super cr...  Sentiment   \n",
      "299   P4R1347                            this stuff is fabulous!  Sentiment   \n",
      "300   P4R1354  This is a lifesaver. I bought this moisturizer...  Sentiment   \n",
      "301   P4R1356  This moisturizer is very good for the body and...  Sentiment   \n",
      "302   P4R1362  works AMAZINGLY to instantly sooth and heal pa...  Sentiment   \n",
      "\n",
      "    Sentiment                                             Phrase        Date  \\\n",
      "0    Negative                 used to be the absolute best cream  2022-11-18   \n",
      "1    Positive     FAB ultra hydrating cream truly does soothe it  2022-10-23   \n",
      "2    Positive                 love the way it makes my skin feel  2022-10-07   \n",
      "3    Positive                                 Ultra Repair cream  2022-09-27   \n",
      "4    Positive                             would highly recommend  2022-09-27   \n",
      "..        ...                                                ...         ...   \n",
      "298  Positive              I found this cream and gave it a try!  2018-12-17   \n",
      "299  Positive                            this stuff is fabulous!  2018-12-15   \n",
      "300  Positive                                  HIGHLY RECOMMEND!  2018-12-05   \n",
      "301  Negative                         donâ€™t recommend for face  2018-12-03   \n",
      "302  Positive  can't live without it in my bag during the win...  2018-11-28   \n",
      "\n",
      "     Rating                              cp  Cluster   L3 Cluster Phrase  \\\n",
      "0         1         use absolute good cream    cream  Ultra Repair cream   \n",
      "1         5  FAB ultra hydrate cream soothe    cream  Ultra Repair cream   \n",
      "2         3         love way make skin feel    cream  Ultra Repair cream   \n",
      "3         2              Ultra Repair cream    cream  Ultra Repair cream   \n",
      "4         2                highly recommend   highly    highly recommend   \n",
      "..      ...                             ...      ...                 ...   \n",
      "298       5             find cream give try    cream  Ultra Repair cream   \n",
      "299       5                  stuff fabulous  product   Love this product   \n",
      "300       5                highly RECOMMEND   highly    highly recommend   \n",
      "301       4                  recommend face    cream  Ultra Repair cream   \n",
      "302       5           live bag winter month  product   Love this product   \n",
      "\n",
      "           sim  \n",
      "0    28.314286  \n",
      "1    36.228571  \n",
      "2    28.314286  \n",
      "3    23.142857  \n",
      "4    11.692308  \n",
      "..         ...  \n",
      "298  30.257143  \n",
      "299  23.244604  \n",
      "300  20.307692  \n",
      "301  27.014286  \n",
      "302  46.381295  \n",
      "\n",
      "[303 rows x 11 columns]\n",
      "Aspect: Odor\n",
      "   Topic  Count                                           Name\n",
      "0      0     77  0_smell_smell smell_medicinal_medicinal smell\n",
      "1      1     77                  1_scent_fragrance_free_strong\n",
      "       Cluster\n",
      "smell       77\n",
      "scent       77\n",
      "  Cluster L3 Cluster Phrase\n",
      "0   scent       had a scent\n",
      "1   smell     doesn't smell \n",
      "\n",
      "    Review ID                                             Review Aspect  \\\n",
      "0        P4R1  Disastrous formula change.\\n\\nI've been using ...   Odor   \n",
      "1       P4R23  Not The Best\\n\\nI was not impressed with this....   Odor   \n",
      "2       P4R24  sensitive skin is tough to manage\\n\\nIt works ...   Odor   \n",
      "3       P4R28  ABSOLUTE NO!!\\n\\nThis cream is very lightweigh...   Odor   \n",
      "4       P4R30  great product\\n\\nVery soothing and moisturizin...   Odor   \n",
      "..        ...                                                ...    ...   \n",
      "149   P4R1350  I bought this in the pink grapefruit scent. It...   Odor   \n",
      "150   P4R1356  This moisturizer is very good for the body and...   Odor   \n",
      "151   P4R1368  The product is very thick. Scent is alright. B...   Odor   \n",
      "152   P4R1371  I have combo/oily skin and this is much too th...   Odor   \n",
      "153   P4R1372  This is amazing!!! I love it because it helps ...   Odor   \n",
      "\n",
      "    Sentiment                          Phrase        Date  Rating  \\\n",
      "0    Positive              scent was pleasant  2022-11-18       1   \n",
      "1    Negative        wasn’t huge on the smell  2022-09-14       5   \n",
      "2    Positive        doesn't have a fragrance  2022-09-11       5   \n",
      "3    Negative                smells like oats  2022-08-31       5   \n",
      "4    Negative         smell like medicine tho  2022-08-28       4   \n",
      "..        ...                             ...         ...     ...   \n",
      "149  Positive                  smells amazing  2018-12-13       5   \n",
      "150  Negative               strong fragrance.  2018-12-03       4   \n",
      "151  Negative               Scent is alright.  2018-11-24       3   \n",
      "152  Positive   isn't any overpowering smell,  2018-11-22       5   \n",
      "153  Positive  doesnâ€™t have a strong scent,  2018-11-22       5   \n",
      "\n",
      "                         cp Cluster L3 Cluster Phrase        sim  \n",
      "0            scent pleasant   scent       had a scent  16.789474  \n",
      "1                huge smell   smell     doesn't smell  19.776316  \n",
      "2                 fragrance   scent       had a scent  18.013158  \n",
      "3                 smell oat   smell     doesn't smell  17.526316  \n",
      "4        smell medicine tho   smell     doesn't smell  19.592105  \n",
      "..                      ...     ...               ...        ...  \n",
      "149           smell amazing   scent       had a scent  17.289474  \n",
      "150        strong fragrance   scent       had a scent  15.881579  \n",
      "151           scent alright   scent       had a scent  17.157895  \n",
      "152         overpower smell   smell     doesn't smell  23.486842  \n",
      "153  doesnâ€ ™ strong scent   scent       had a scent  21.394737  \n",
      "\n",
      "[154 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Texture\n",
      "    Topic  Count                                               Name\n",
      "0       0     76  0_hydrate hydrate_hydrate hydrate hydrate_hydr...\n",
      "1       1     69  1_moisturize_moisturize moisturize_moisturize ...\n",
      "2       2     45           2_skin hydrate_hydrate skin_hydrate_skin\n",
      "3       3     39      3_thick_thick thick_thick thick thick_formula\n",
      "4       4     36                4_feel heavy_heavy_feel_lightweight\n",
      "5       5     45                       5_soft_skin soft_skin_smooth\n",
      "6       6     33  6_greasy greasy_greasy greasy greasy_greasy_farth\n",
      "7       7     29  7_feel greasy_greasy feel_greasy_greasy feel g...\n",
      "8       8     29    8_heavy_heavy heavy_heavy skin heavy_heavy skin\n",
      "9       9     35                    9_oily_oily oily_make oily_make\n",
      "10     10     27  10_feel hydrate_skin feel hydrate_hydrate day_...\n",
      "11     11     26  11_moisturize skin_skin moisturize_moisturize_...\n",
      "12     12     26             12_absorb_absorb well_well absorb_well\n",
      "13     13     26             13_cream_thick cream_cream thick_thick\n",
      "14     14     29             14_absorb skin_absorb_soak_skin absorb\n",
      "15     15     24  15_absorb quickly_quickly_absorb quickly absor...\n",
      "16     16     27              16_oily greasy_oily_doesn_greasy oily\n",
      "17     17     19     17_texture_light texture_texture texture_light\n",
      "18     18     19     18_non greasy_non_greasy non_greasy non greasy\n",
      "19     19     21         19_creamy_whip_creamy texture_whip texture\n",
      "20     20     16       20_residue_residue leave_leave_leave residue\n",
      "21     21     20  21_greasy leave_leave greasy_greasy leave grea...\n",
      "22     22     16           22_sticky_feel sticky_face_sticky sticky\n",
      "23     23     13           23_sink_sink fast_quickly sink_sink sink\n",
      "24     24     20                24_light_thick feel_feel thick_glow\n",
      "25     25     31             25_soothe_soothe soothe_clog_clog pore\n",
      "26     26     21                       26_sit_skin sit_top_sit skin\n",
      "27     27     28               27_smooth_consistency_go_smooth feel\n",
      "28     28     15  28_leave skin_greasy leave skin_leave_greasy l...\n",
      "29     29     32  29_hydrate_intense_intense hydrate_hydrate enough\n",
      "                 Cluster\n",
      "hydrate              108\n",
      "moisturize            69\n",
      "skin hydrate          45\n",
      "soft                  45\n",
      "thick                 39\n",
      "feel heavy            36\n",
      "oily                  35\n",
      "greasy                33\n",
      "soothe                31\n",
      "heavy                 29\n",
      "feel greasy           29\n",
      "absorb skin           29\n",
      "smooth                28\n",
      "feel hydrate          27\n",
      "oily greasy           27\n",
      "cream                 26\n",
      "absorb                26\n",
      "moisturize skin       26\n",
      "absorb quickly        24\n",
      "sit                   21\n",
      "creamy                21\n",
      "greasy leave          20\n",
      "light                 20\n",
      "non greasy            19\n",
      "texture               19\n",
      "sticky                16\n",
      "residue               16\n",
      "leave skin            15\n",
      "sink                  13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1800efea4f0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m l = detailed_output(df,map_dict=dP4,client='P4',take_sentiment=False,ng_range=(1,3),words_per_topic=5,words_to_remove=[]\n\u001b[0m\u001b[0;32m      2\u001b[0m                     ,compress=False,create_exl=True,version='v1')\n",
      "\u001b[1;32m<ipython-input-27-51b41be7d105>\u001b[0m in \u001b[0;36mdetailed_output\u001b[1;34m(df, map_dict, client, take_sentiment, flag_rating, compress, words_per_topic, ng_range, words_to_remove, date, version, create_exl)\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                         \u001b[0msim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                                 \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjellyfish\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevenshtein_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Phrase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Phrase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3015\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3069\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l = detailed_output(df,map_dict=dP4,client='P4',take_sentiment=False,ng_range=(1,3),words_per_topic=5,words_to_remove=[]\n",
    "                    ,compress=False,create_exl=True,version='v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a91eab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Started\n",
      "\n",
      "BERTopic Clustering will take a while\n",
      "Sentiment: Positive Aspect: Ingredients\n",
      "   Topic  Count                                               Name\n",
      "0      0     62                  0_ingredient_formula_clean_change\n",
      "1      1     20     1_eucalyptus_oil_eucalyptus oil_oil eucalyptus\n",
      "2      2     16  2_colloidal_colloidal oatmeal_oatmeal_colloida...\n",
      "            Cluster\n",
      "ingredient       62\n",
      "eucalyptus       20\n",
      "colloidal        16\n",
      "      Cluster    L3 Cluster Phrase\n",
      "0  ingredient  ove the ingredients\n",
      "1  eucalyptus      eucalyptus oil.\n",
      "2   colloidal    colloidal oatmeal \n",
      "\n",
      "Sentiment: Positive Aspect: Brand\n",
      "   Topic  Count                                         Name\n",
      "0      0     37              0_fab_product_cream_fab product\n",
      "1      1     23                1_aid_beauty_aid beauty_thank\n",
      "2      2     19  2_brand_brand brand_vegan_brand brand vegan\n",
      "       Cluster\n",
      "fab         37\n",
      "aid         23\n",
      "brand       19\n",
      "   Cluster        L3 Cluster Phrase\n",
      "0      fab      fan of FAB products\n",
      "5      aid  Thanks First Aid Beauty\n",
      "11   brand    discovered this brand \n",
      "\n",
      "Sentiment: Positive Aspect: Purchase\n",
      "   Topic  Count                                               Name\n",
      "0      0     84                           0_buy_size_year_purchase\n",
      "1      1     45           1_purchase_buy_purchase purchase_buy buy\n",
      "2      2     27  2_repurchase_repurchase repurchase_repurchase ...\n",
      "            Cluster\n",
      "buy              84\n",
      "purchase         45\n",
      "repurchase       27\n",
      "      Cluster   L3 Cluster Phrase\n",
      "0         buy  buy the large tube\n",
      "2  repurchase     will repurchase\n",
      "3    purchase    not buy it again \n",
      "\n",
      "Sentiment: Positive Aspect: Demographic\n",
      "   Topic  Count                                               Name\n",
      "0      0     74                        0_old_year_year old_husband\n",
      "1      1     63                        1_dry_live_dry winter_cream\n",
      "2      2     32  2_winter_winter winter_especially winter winte...\n",
      "3      3     19  3_month_winter month_month winter_month winter...\n",
      "4      4     14             4_cold_weather_winter cold_cold winter\n",
      "        Cluster\n",
      "old          74\n",
      "dry          63\n",
      "winter       32\n",
      "month        19\n",
      "cold         14\n",
      "   Cluster    L3 Cluster Phrase\n",
      "0     cold  cold winter weather\n",
      "1      old        my 7 year old\n",
      "2   winter        in the winter\n",
      "8      dry       very dry state\n",
      "21   month        winter months \n",
      "\n",
      "Sentiment: Positive Aspect: Sentiment\n",
      "   Topic  Count                                               Name\n",
      "0      0    140                          0_product_love_stuff_hype\n",
      "1      1     71                            1_cream_face_skin_ultra\n",
      "2      2     34            2_holy_holy grail_grail_holy grail holy\n",
      "3      3     23  3_moisturizer_love moisturizer_good moisturize...\n",
      "4      4     21  4_recommend_recommend recommend_recommend reco...\n",
      "5      5     14  5_highly_highly recommend_recommend highly_rec...\n",
      "             Cluster\n",
      "product          140\n",
      "cream             71\n",
      "holy              34\n",
      "moisturizer       23\n",
      "recommend         21\n",
      "highly            14\n",
      "        Cluster      L3 Cluster Phrase\n",
      "0         cream     Ultra Repair cream\n",
      "4        highly       highly recommend\n",
      "5       product      Love this product\n",
      "7   moisturizer  love this moisturizer\n",
      "22         holy             holy grail\n",
      "25    recommend        Don’t recommend \n",
      "\n",
      "Sentiment: Positive Aspect: Odor\n",
      "   Topic  Count                                           Name\n",
      "0      0     77  0_smell_smell smell_medicinal_medicinal smell\n",
      "1      1     77                  1_scent_fragrance_free_strong\n",
      "       Cluster\n",
      "smell       77\n",
      "scent       77\n",
      "  Cluster L3 Cluster Phrase\n",
      "0   scent       had a scent\n",
      "1   smell     doesn't smell \n",
      "\n",
      "Sentiment: Positive Aspect: Texture\n",
      "    Topic  Count                                               Name\n",
      "0       0     76  0_hydrate hydrate_hydrate hydrate hydrate_hydr...\n",
      "1       1     69  1_moisturize_moisturize moisturize_moisturize ...\n",
      "2       2     45           2_skin hydrate_hydrate skin_hydrate_skin\n",
      "3       3     39      3_thick_thick thick_thick thick thick_formula\n",
      "4       4     36                4_feel heavy_heavy_feel_lightweight\n",
      "5       5     45                       5_soft_skin soft_skin_smooth\n",
      "6       6     33  6_greasy greasy_greasy greasy greasy_greasy_farth\n",
      "7       7     29  7_feel greasy_greasy feel_greasy_greasy feel g...\n",
      "8       8     29    8_heavy_heavy heavy_heavy skin heavy_heavy skin\n",
      "9       9     35                    9_oily_oily oily_make oily_make\n",
      "10     10     27  10_feel hydrate_skin feel hydrate_hydrate day_...\n",
      "11     11     26  11_moisturize skin_skin moisturize_moisturize_...\n",
      "12     12     26             12_absorb_absorb well_well absorb_well\n",
      "13     13     26             13_cream_thick cream_cream thick_thick\n",
      "14     14     29             14_absorb skin_absorb_soak_skin absorb\n",
      "15     15     24  15_absorb quickly_quickly_absorb quickly absor...\n",
      "16     16     27              16_oily greasy_oily_doesn_greasy oily\n",
      "17     17     19     17_texture_light texture_texture texture_light\n",
      "18     18     19     18_non greasy_non_greasy non_greasy non greasy\n",
      "19     19     21         19_creamy_whip_creamy texture_whip texture\n",
      "20     20     16       20_residue_residue leave_leave_leave residue\n",
      "21     21     20  21_greasy leave_leave greasy_greasy leave grea...\n",
      "22     22     16           22_sticky_feel sticky_face_sticky sticky\n",
      "23     23     13           23_sink_sink fast_quickly sink_sink sink\n",
      "24     24     20                24_light_thick feel_feel thick_glow\n",
      "25     25     31             25_soothe_soothe soothe_clog_clog pore\n",
      "26     26     21                       26_sit_skin sit_top_sit skin\n",
      "27     27     28               27_smooth_consistency_go_smooth feel\n",
      "28     28     15  28_leave skin_greasy leave skin_leave_greasy l...\n",
      "29     29     32  29_hydrate_intense_intense hydrate_hydrate enough\n",
      "                 Cluster\n",
      "hydrate              108\n",
      "moisturize            69\n",
      "skin hydrate          45\n",
      "soft                  45\n",
      "thick                 39\n",
      "feel heavy            36\n",
      "oily                  35\n",
      "greasy                33\n",
      "soothe                31\n",
      "heavy                 29\n",
      "feel greasy           29\n",
      "absorb skin           29\n",
      "smooth                28\n",
      "feel hydrate          27\n",
      "oily greasy           27\n",
      "cream                 26\n",
      "absorb                26\n",
      "moisturize skin       26\n",
      "absorb quickly        24\n",
      "sit                   21\n",
      "creamy                21\n",
      "greasy leave          20\n",
      "light                 20\n",
      "non greasy            19\n",
      "texture               19\n",
      "sticky                16\n",
      "residue               16\n",
      "leave skin            15\n",
      "sink                  13\n",
      "             Cluster                L3 Cluster Phrase\n",
      "0               soft                     skin so soft\n",
      "1         non greasy                       not greasy\n",
      "2            texture                 like the texture\n",
      "3       feel hydrate            skin feel so hydrated\n",
      "7         moisturize                very moisturizing\n",
      "8              cream                      thick cream\n",
      "9     absorb quickly                  absorbs quickly\n",
      "10             thick                    not too thick\n",
      "11           hydrate                   very hydrating\n",
      "16       absorb skin            absorbs into the skin\n",
      "18            soothe                  soothes my skin\n",
      "19              oily                     not too oily\n",
      "22            creamy                 thick and creamy\n",
      "23            sticky              doesn't feel sticky\n",
      "29            smooth                   goes on smooth\n",
      "33           residue          doesn’t leave a residue\n",
      "37        feel heavy               doesn't feel heavy\n",
      "40      greasy leave         without leaving a greasy\n",
      "41             heavy                        too heavy\n",
      "43      skin hydrate                 hydrated my skin\n",
      "45            absorb                    absorbs well,\n",
      "51       oily greasy             Not heavy or greasy,\n",
      "58       feel greasy              doesn't feel greasy\n",
      "60              sink                  sets in quickly\n",
      "90   moisturize skin               moisturize my skin\n",
      "102              sit                 sits on the skin\n",
      "141            light                      feels light\n",
      "162           greasy                       not greasy\n",
      "226       leave skin  does not leave your skin greasy \n",
      "\n",
      "Sentiment: Positive Aspect: Application\n",
      "   Topic  Count                                            Name\n",
      "0      0    165                     0_body_moisturizer_use_hand\n",
      "1      1     43                 1_face_face face_face neck_neck\n",
      "2      2     31                          2_makeup_top_well_look\n",
      "3      3     21                        3_go_foundation_long_way\n",
      "4      4     13  4_formula_change_change formula_formula change\n",
      "         Cluster\n",
      "body         165\n",
      "face          43\n",
      "makeup        31\n",
      "go            21\n",
      "formula       13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cluster        L3 Cluster Phrase\n",
      "0    makeup  works well under makeup\n",
      "1      body         my feet and legs\n",
      "2   formula    changed their formula\n",
      "10     face                  my face\n",
      "19       go    little goes a long wa \n",
      "\n",
      "Sentiment: Positive Aspect: Price\n",
      "   Topic  Count                                   Name\n",
      "0      0    134            0_price_great_product_point\n",
      "1      1     26  1_worth_worth price_price worth_price\n",
      "       Cluster\n",
      "price      134\n",
      "worth       26\n",
      "  Cluster    L3 Cluster Phrase\n",
      "0   price   Good for the price\n",
      "5   worth  not worth the price \n",
      "\n",
      "Sentiment: Positive Aspect: Skin_type\n",
      "    Topic  Count                                               Name\n",
      "0       0     76  0_skin sensitive skin_sensitive skin sensitive...\n",
      "1       1     72     1_skin dry skin_dry skin dry_skin dry_dry skin\n",
      "2       2     56                       2_dry_dry skin_skin_skin dry\n",
      "3       3     34          3_oily_oily skin_skin oily_skin oily skin\n",
      "4       4     30  4_combination skin_combination skin combinatio...\n",
      "5       5     26  5_dry sensitive_dry sensitive skin_skin dry se...\n",
      "6       6     26  6_extremely dry skin_extremely dry_skin extrem...\n",
      "7       7     24      7_combo_combo skin_skin combo_skin combo skin\n",
      "8       8     20      8_oily_combination_combination oily_oily skin\n",
      "9       9     13              9_dry skin_dry_great_skin perfect dry\n",
      "10     10     20  10_great sensitive_sensitive_sensitive skin gr...\n",
      "                    Cluster\n",
      "skin sensitive           76\n",
      "skin dry                 72\n",
      "dry                      56\n",
      "oily                     54\n",
      "combination skin         30\n",
      "dry sensitive            26\n",
      "extremely dry skin       26\n",
      "combo                    24\n",
      "great sensitive          20\n",
      "dry skin                 13\n",
      "               Cluster         L3 Cluster Phrase\n",
      "0       skin sensitive            sensitive skin\n",
      "1             skin dry                  dry skin\n",
      "3                  dry             very dry skin\n",
      "8   extremely dry skin        extremely dry skin\n",
      "9                 oily                 oily skin\n",
      "10               combo           combination ski\n",
      "19       dry sensitive        dry sensitive skin\n",
      "28     great sensitive  great for sensitive skin\n",
      "29            dry skin       great for dry skin!\n",
      "38    combination skin          combination skin \n",
      "\n",
      "Sentiment: Positive Aspect: Skin\n",
      "    Topic  Count                                               Name\n",
      "0       0     86             0_acne_hormonal_breakout_hormonal acne\n",
      "1       1     98                       1_skin_soft_skin skin_smooth\n",
      "2       2     55  2_eczema_eczema eczema_eczema eczema eczema_ke...\n",
      "3       3     52                 3_redness_reduce redness_go_reduce\n",
      "4       4     47               4_dry dry_dry_dry dry dry_mostly dry\n",
      "5       5     35  5_rosacea_rosacea rosacea_skin rosacea_rosacea...\n",
      "6       6     35                 6_flaky_flake_flaky skin_dry flaky\n",
      "7       7     34                    7_redness_calm redness_calm_red\n",
      "8       8     33  8_acne prone skin_prone skin_skin acne prone_p...\n",
      "9       9     33                    9_dry patch_patch_patch dry_dry\n",
      "10     10     26    10_dry skin_dry skin dry_skin dry_skin dry skin\n",
      "11     11     31  11_eczema_eczema prone_soothe eczema_eczema pr...\n",
      "12     12     22                  12_itchy_itch_dry itchy_itchiness\n",
      "13     13     21              13_pore_clog_clog pore_clog pore clog\n",
      "14     14     20  14_moisture_moisture barrier_barrier_damage mo...\n",
      "15     15     20  15_irritation_irritated_product subside_reduce...\n",
      "16     16     19        16_winter_dry winter_winter skin_winter dry\n",
      "17     17     18                  17_red_skin red_redness skin_skin\n",
      "18     18     18  18_dryness_help dryness_dryness help_dryness h...\n",
      "19     19     17               19_hand_dry hand_hand feel_hand hand\n",
      "20     20     17                     20_break_hour_break break_work\n",
      "21     21     22    21_crack_crack skin_crack skin crack_crack heal\n",
      "22     22     15  22_acne prone acne_prone acne prone_prone acne...\n",
      "23     23     22  23_sensitive_sensitive sensitive_sensitive dry...\n",
      "24     24     15       24_moisturizer_moisturize_plump_moisturizing\n",
      "25     25     12  25_rash_rash rash_rash rash disappear_rash dis...\n",
      "26     26     15  26_dermatitis_perioral dermatitis_perioral_der...\n",
      "27     27     12             27_dry spot_spot_spot dry_dry spot dry\n",
      "28     28     11  28_dry pretty dry_incredibly dry_incredibly_dr...\n",
      "29     29     15                     29_eczema hand_eczema_arm_hand\n",
      "                 Cluster\n",
      "skin                  98\n",
      "acne                  86\n",
      "eczema                86\n",
      "redness               86\n",
      "dry                   47\n",
      "rosacea               35\n",
      "flaky                 35\n",
      "acne prone skin       33\n",
      "dry patch             33\n",
      "dry skin              26\n",
      "sensitive             22\n",
      "itchy                 22\n",
      "crack                 22\n",
      "pore                  21\n",
      "irritation            20\n",
      "moisture              20\n",
      "winter                19\n",
      "red                   18\n",
      "dryness               18\n",
      "hand                  17\n",
      "break                 17\n",
      "dermatitis            15\n",
      "eczema hand           15\n",
      "moisturizer           15\n",
      "acne prone            15\n",
      "rash                  12\n",
      "dry spot              12\n",
      "dry pretty            11\n",
      "             Cluster       L3 Cluster Phrase\n",
      "0               acne              treat acne\n",
      "1             eczema             have eczema\n",
      "3            dryness     helped with dryness\n",
      "4               hand          very dry hands\n",
      "5                dry                very dry\n",
      "6          sensitive           dry sensitive\n",
      "7        eczema hand      eczema on my hands\n",
      "8            rosacea            have rosacea\n",
      "9            redness          reduce redness\n",
      "10   acne prone skin         acne prone skin\n",
      "16        acne prone              acne prone\n",
      "22        dry pretty              pretty dry\n",
      "27         dry patch             dry patches\n",
      "29              skin          eas on my skin\n",
      "30        dermatitis     perioral dermatitis\n",
      "31          moisture       locks in moisture\n",
      "35          dry spot               dry spots\n",
      "36          dry skin        skin is very dry\n",
      "41             itchy         wintery itching\n",
      "43            winter  really dry winter skin\n",
      "50               red   Made my skin very red\n",
      "61             flaky          dry flaky skin\n",
      "63             crack            cracked skin\n",
      "109      moisturizer     ultra moisturizing!\n",
      "128             pore          clogs my pores\n",
      "129       irritation        skin irritations\n",
      "170             rash           horrible rash\n",
      "374            break           broke me out. \n",
      "\n",
      "Sentiment: Positive Aspect: Motivation\n",
      "   Topic  Count                                           Name\n",
      "0      0     60                      0_review_good_read_friend\n",
      "1      1     35                1_sample_get_get sample_receive\n",
      "2      2     24              2_moisturizer_skincare_skin_hyram\n",
      "3      3     40                            3_sale_size_get_buy\n",
      "4      4     17  4_sephora_recommend_sephora employee_employee\n",
      "             Cluster\n",
      "review            60\n",
      "sale              40\n",
      "sample            35\n",
      "moisturizer       24\n",
      "sephora           17\n",
      "       Cluster        L3 Cluster Phrase\n",
      "0         sale  got this with my points\n",
      "1  moisturizer      morning moisturizer\n",
      "3       review      reading the reviews\n",
      "8      sephora        went into Sephora\n",
      "9       sample     got this as a sample \n",
      "\n",
      "Sentiment: Positive Aspect: Competitor\n",
      "   Topic  Count                              Name\n",
      "0      0    102  0_cream_moisturizer_tatcha_drunk\n",
      "1      1     27      1_cerave_aveeno_dr_vanicream\n",
      "        Cluster\n",
      "cream       102\n",
      "cerave       27\n",
      "  Cluster L3 Cluster Phrase\n",
      "0   cream     steroid cream\n",
      "2  cerave            Cerave \n",
      "\n",
      "Sentiment: Positive Aspect: Allergy\n",
      "   Topic  Count                                               Name\n",
      "0      0     74   0_break_break break_break break break_make break\n",
      "1      1     64                            1_pimple_bump_peel_pore\n",
      "2      2     46             2_burn_sensation_tingle_burn sensation\n",
      "3      3     28                   3_pill_pille_pill pill_tend pill\n",
      "4      4     30                 4_irritate_skin_irritated_reaction\n",
      "5      5     25  5_breakout_breakout make_breakout make breakou...\n",
      "6      6     12                 6_skin break_skin_break_break skin\n",
      "            Cluster\n",
      "break            74\n",
      "pimple           64\n",
      "burn             46\n",
      "irritate         30\n",
      "pill             28\n",
      "breakout         25\n",
      "skin break       12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Cluster       L3 Cluster Phrase\n",
      "0       pimple          clogs my pores\n",
      "1         pill           tends to pill\n",
      "3     breakout       with no breakouts\n",
      "5         burn       burning sensation\n",
      "20    irritate       irritated my skin\n",
      "27       break    doesn't break me out\n",
      "36  skin break  make my skin break out \n",
      "\n",
      "Sentiment: Positive Aspect: Packaging\n",
      "   Topic  Count                       Name\n",
      "0      0     82          0_tube_tub_oz_jar\n",
      "1      1     51  1_size_last_product_month\n",
      "      Cluster\n",
      "tube       82\n",
      "size       51\n",
      "  Cluster   L3 Cluster Phrase\n",
      "0    tube  more than the tube\n",
      "1    size  lasts a few months \n",
      "\n",
      "Sentiment: Positive Aspect: Performance\n",
      "   Topic  Count                             Name\n",
      "0      0     71           0_skin_repair_dry_feel\n",
      "1      1     29  1_calm_calm skin_clog pore_clog\n",
      "2      2     24         2_last_product_time_long\n",
      "      Cluster\n",
      "skin       71\n",
      "calm       29\n",
      "last       24\n",
      "   Cluster  L3 Cluster Phrase\n",
      "0     skin     Healed my skin\n",
      "2     last  Lasts a long time\n",
      "12    calm      calms my skin \n",
      "\n",
      "Sentiment: Negative Aspect: Ingredients\n",
      "   Topic  Count                                               Name\n",
      "0      0     62                  0_ingredient_formula_clean_change\n",
      "1      1     20     1_eucalyptus_oil_eucalyptus oil_oil eucalyptus\n",
      "2      2     16  2_colloidal_colloidal oatmeal_oatmeal_colloida...\n",
      "            Cluster\n",
      "ingredient       62\n",
      "eucalyptus       20\n",
      "colloidal        16\n",
      "      Cluster    L3 Cluster Phrase\n",
      "0  ingredient  ove the ingredients\n",
      "1  eucalyptus      eucalyptus oil.\n",
      "2   colloidal    colloidal oatmeal \n",
      "\n",
      "Sentiment: Negative Aspect: Brand\n",
      "   Topic  Count                                         Name\n",
      "0      0     37              0_fab_product_cream_fab product\n",
      "1      1     23                1_aid_beauty_aid beauty_thank\n",
      "2      2     19  2_brand_brand brand_vegan_brand brand vegan\n",
      "       Cluster\n",
      "fab         37\n",
      "aid         23\n",
      "brand       19\n",
      "   Cluster        L3 Cluster Phrase\n",
      "0      fab      fan of FAB products\n",
      "5      aid  Thanks First Aid Beauty\n",
      "11   brand    discovered this brand \n",
      "\n",
      "Sentiment: Negative Aspect: Purchase\n",
      "   Topic  Count                                               Name\n",
      "0      0     84                           0_buy_size_year_purchase\n",
      "1      1     45           1_purchase_buy_purchase purchase_buy buy\n",
      "2      2     27  2_repurchase_repurchase repurchase_repurchase ...\n",
      "            Cluster\n",
      "buy              84\n",
      "purchase         45\n",
      "repurchase       27\n",
      "      Cluster   L3 Cluster Phrase\n",
      "0         buy  buy the large tube\n",
      "2  repurchase     will repurchase\n",
      "3    purchase    not buy it again \n",
      "\n",
      "Sentiment: Negative Aspect: Demographic\n",
      "   Topic  Count                                               Name\n",
      "0      0     74                        0_old_year_year old_husband\n",
      "1      1     63                        1_dry_live_dry winter_cream\n",
      "2      2     32  2_winter_winter winter_especially winter winte...\n",
      "3      3     19  3_month_winter month_month winter_month winter...\n",
      "4      4     14             4_cold_weather_winter cold_cold winter\n",
      "        Cluster\n",
      "old          74\n",
      "dry          63\n",
      "winter       32\n",
      "month        19\n",
      "cold         14\n",
      "   Cluster    L3 Cluster Phrase\n",
      "0     cold  cold winter weather\n",
      "1      old        my 7 year old\n",
      "2   winter        in the winter\n",
      "8      dry       very dry state\n",
      "21   month        winter months \n",
      "\n",
      "Sentiment: Negative Aspect: Sentiment\n",
      "   Topic  Count                                               Name\n",
      "0      0    140                          0_product_love_stuff_hype\n",
      "1      1     71                            1_cream_face_skin_ultra\n",
      "2      2     34            2_holy_holy grail_grail_holy grail holy\n",
      "3      3     23  3_moisturizer_love moisturizer_good moisturize...\n",
      "4      4     21  4_recommend_recommend recommend_recommend reco...\n",
      "5      5     14  5_highly_highly recommend_recommend highly_rec...\n",
      "             Cluster\n",
      "product          140\n",
      "cream             71\n",
      "holy              34\n",
      "moisturizer       23\n",
      "recommend         21\n",
      "highly            14\n",
      "        Cluster      L3 Cluster Phrase\n",
      "0         cream     Ultra Repair cream\n",
      "4        highly       highly recommend\n",
      "5       product      Love this product\n",
      "7   moisturizer  love this moisturizer\n",
      "22         holy             holy grail\n",
      "25    recommend        Don’t recommend \n",
      "\n",
      "Sentiment: Negative Aspect: Odor\n",
      "   Topic  Count                                           Name\n",
      "0      0     77  0_smell_smell smell_medicinal_medicinal smell\n",
      "1      1     77                  1_scent_fragrance_free_strong\n",
      "       Cluster\n",
      "smell       77\n",
      "scent       77\n",
      "  Cluster L3 Cluster Phrase\n",
      "0   scent       had a scent\n",
      "1   smell     doesn't smell \n",
      "\n",
      "Sentiment: Negative Aspect: Texture\n",
      "    Topic  Count                                               Name\n",
      "0       0     76  0_hydrate hydrate_hydrate hydrate hydrate_hydr...\n",
      "1       1     69  1_moisturize_moisturize moisturize_moisturize ...\n",
      "2       2     45           2_skin hydrate_hydrate skin_hydrate_skin\n",
      "3       3     39      3_thick_thick thick_thick thick thick_formula\n",
      "4       4     36                4_feel heavy_heavy_feel_lightweight\n",
      "5       5     45                       5_soft_skin soft_skin_smooth\n",
      "6       6     33  6_greasy greasy_greasy greasy greasy_greasy_farth\n",
      "7       7     29  7_feel greasy_greasy feel_greasy_greasy feel g...\n",
      "8       8     29    8_heavy_heavy heavy_heavy skin heavy_heavy skin\n",
      "9       9     35                    9_oily_oily oily_make oily_make\n",
      "10     10     27  10_feel hydrate_skin feel hydrate_hydrate day_...\n",
      "11     11     26  11_moisturize skin_skin moisturize_moisturize_...\n",
      "12     12     26             12_absorb_absorb well_well absorb_well\n",
      "13     13     26             13_cream_thick cream_cream thick_thick\n",
      "14     14     29             14_absorb skin_absorb_soak_skin absorb\n",
      "15     15     24  15_absorb quickly_quickly_absorb quickly absor...\n",
      "16     16     27              16_oily greasy_oily_doesn_greasy oily\n",
      "17     17     19     17_texture_light texture_texture texture_light\n",
      "18     18     19     18_non greasy_non_greasy non_greasy non greasy\n",
      "19     19     21         19_creamy_whip_creamy texture_whip texture\n",
      "20     20     16       20_residue_residue leave_leave_leave residue\n",
      "21     21     20  21_greasy leave_leave greasy_greasy leave grea...\n",
      "22     22     16           22_sticky_feel sticky_face_sticky sticky\n",
      "23     23     13           23_sink_sink fast_quickly sink_sink sink\n",
      "24     24     20                24_light_thick feel_feel thick_glow\n",
      "25     25     31             25_soothe_soothe soothe_clog_clog pore\n",
      "26     26     21                       26_sit_skin sit_top_sit skin\n",
      "27     27     28               27_smooth_consistency_go_smooth feel\n",
      "28     28     15  28_leave skin_greasy leave skin_leave_greasy l...\n",
      "29     29     32  29_hydrate_intense_intense hydrate_hydrate enough\n",
      "                 Cluster\n",
      "hydrate              108\n",
      "moisturize            69\n",
      "skin hydrate          45\n",
      "soft                  45\n",
      "thick                 39\n",
      "feel heavy            36\n",
      "oily                  35\n",
      "greasy                33\n",
      "soothe                31\n",
      "heavy                 29\n",
      "feel greasy           29\n",
      "absorb skin           29\n",
      "smooth                28\n",
      "feel hydrate          27\n",
      "oily greasy           27\n",
      "cream                 26\n",
      "absorb                26\n",
      "moisturize skin       26\n",
      "absorb quickly        24\n",
      "sit                   21\n",
      "creamy                21\n",
      "greasy leave          20\n",
      "light                 20\n",
      "non greasy            19\n",
      "texture               19\n",
      "sticky                16\n",
      "residue               16\n",
      "leave skin            15\n",
      "sink                  13\n",
      "             Cluster                L3 Cluster Phrase\n",
      "0               soft                     skin so soft\n",
      "1         non greasy                       not greasy\n",
      "2            texture                 like the texture\n",
      "3       feel hydrate            skin feel so hydrated\n",
      "7         moisturize                very moisturizing\n",
      "8              cream                      thick cream\n",
      "9     absorb quickly                  absorbs quickly\n",
      "10             thick                    not too thick\n",
      "11           hydrate                   very hydrating\n",
      "16       absorb skin            absorbs into the skin\n",
      "18            soothe                  soothes my skin\n",
      "19              oily                     not too oily\n",
      "22            creamy                 thick and creamy\n",
      "23            sticky              doesn't feel sticky\n",
      "29            smooth                   goes on smooth\n",
      "33           residue          doesn’t leave a residue\n",
      "37        feel heavy               doesn't feel heavy\n",
      "40      greasy leave         without leaving a greasy\n",
      "41             heavy                        too heavy\n",
      "43      skin hydrate                 hydrated my skin\n",
      "45            absorb                    absorbs well,\n",
      "51       oily greasy             Not heavy or greasy,\n",
      "58       feel greasy              doesn't feel greasy\n",
      "60              sink                  sets in quickly\n",
      "90   moisturize skin               moisturize my skin\n",
      "102              sit                 sits on the skin\n",
      "141            light                      feels light\n",
      "162           greasy                       not greasy\n",
      "226       leave skin  does not leave your skin greasy \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative Aspect: Application\n",
      "   Topic  Count                                            Name\n",
      "0      0    165                     0_body_moisturizer_use_hand\n",
      "1      1     43                 1_face_face face_face neck_neck\n",
      "2      2     31                          2_makeup_top_well_look\n",
      "3      3     21                        3_go_foundation_long_way\n",
      "4      4     13  4_formula_change_change formula_formula change\n",
      "         Cluster\n",
      "body         165\n",
      "face          43\n",
      "makeup        31\n",
      "go            21\n",
      "formula       13\n",
      "    Cluster        L3 Cluster Phrase\n",
      "0    makeup  works well under makeup\n",
      "1      body         my feet and legs\n",
      "2   formula    changed their formula\n",
      "10     face                  my face\n",
      "19       go    little goes a long wa \n",
      "\n",
      "Sentiment: Negative Aspect: Price\n",
      "   Topic  Count                                   Name\n",
      "0      0    134            0_price_great_product_point\n",
      "1      1     26  1_worth_worth price_price worth_price\n",
      "       Cluster\n",
      "price      134\n",
      "worth       26\n",
      "  Cluster    L3 Cluster Phrase\n",
      "0   price   Good for the price\n",
      "5   worth  not worth the price \n",
      "\n",
      "Sentiment: Negative Aspect: Skin_type\n",
      "    Topic  Count                                               Name\n",
      "0       0     76  0_skin sensitive skin_sensitive skin sensitive...\n",
      "1       1     72     1_skin dry skin_dry skin dry_skin dry_dry skin\n",
      "2       2     56                       2_dry_dry skin_skin_skin dry\n",
      "3       3     34          3_oily_oily skin_skin oily_skin oily skin\n",
      "4       4     30  4_combination skin_combination skin combinatio...\n",
      "5       5     26  5_dry sensitive_dry sensitive skin_skin dry se...\n",
      "6       6     26  6_extremely dry skin_extremely dry_skin extrem...\n",
      "7       7     24      7_combo_combo skin_skin combo_skin combo skin\n",
      "8       8     20      8_oily_combination_combination oily_oily skin\n",
      "9       9     13              9_dry skin_dry_great_skin perfect dry\n",
      "10     10     20  10_great sensitive_sensitive_sensitive skin gr...\n",
      "                    Cluster\n",
      "skin sensitive           76\n",
      "skin dry                 72\n",
      "dry                      56\n",
      "oily                     54\n",
      "combination skin         30\n",
      "dry sensitive            26\n",
      "extremely dry skin       26\n",
      "combo                    24\n",
      "great sensitive          20\n",
      "dry skin                 13\n",
      "               Cluster         L3 Cluster Phrase\n",
      "0       skin sensitive            sensitive skin\n",
      "1             skin dry                  dry skin\n",
      "3                  dry             very dry skin\n",
      "8   extremely dry skin        extremely dry skin\n",
      "9                 oily                 oily skin\n",
      "10               combo           combination ski\n",
      "19       dry sensitive        dry sensitive skin\n",
      "28     great sensitive  great for sensitive skin\n",
      "29            dry skin       great for dry skin!\n",
      "38    combination skin          combination skin \n",
      "\n",
      "Sentiment: Negative Aspect: Skin\n",
      "    Topic  Count                                               Name\n",
      "0       0     86             0_acne_hormonal_breakout_hormonal acne\n",
      "1       1     98                       1_skin_soft_skin skin_smooth\n",
      "2       2     55  2_eczema_eczema eczema_eczema eczema eczema_ke...\n",
      "3       3     52                 3_redness_reduce redness_go_reduce\n",
      "4       4     47               4_dry dry_dry_dry dry dry_mostly dry\n",
      "5       5     35  5_rosacea_rosacea rosacea_skin rosacea_rosacea...\n",
      "6       6     35                 6_flaky_flake_flaky skin_dry flaky\n",
      "7       7     34                    7_redness_calm redness_calm_red\n",
      "8       8     33  8_acne prone skin_prone skin_skin acne prone_p...\n",
      "9       9     33                    9_dry patch_patch_patch dry_dry\n",
      "10     10     26    10_dry skin_dry skin dry_skin dry_skin dry skin\n",
      "11     11     31  11_eczema_eczema prone_soothe eczema_eczema pr...\n",
      "12     12     22                  12_itchy_itch_dry itchy_itchiness\n",
      "13     13     21              13_pore_clog_clog pore_clog pore clog\n",
      "14     14     20  14_moisture_moisture barrier_barrier_damage mo...\n",
      "15     15     20  15_irritation_irritated_product subside_reduce...\n",
      "16     16     19        16_winter_dry winter_winter skin_winter dry\n",
      "17     17     18                  17_red_skin red_redness skin_skin\n",
      "18     18     18  18_dryness_help dryness_dryness help_dryness h...\n",
      "19     19     17               19_hand_dry hand_hand feel_hand hand\n",
      "20     20     17                     20_break_hour_break break_work\n",
      "21     21     22    21_crack_crack skin_crack skin crack_crack heal\n",
      "22     22     15  22_acne prone acne_prone acne prone_prone acne...\n",
      "23     23     22  23_sensitive_sensitive sensitive_sensitive dry...\n",
      "24     24     15       24_moisturizer_moisturize_plump_moisturizing\n",
      "25     25     12  25_rash_rash rash_rash rash disappear_rash dis...\n",
      "26     26     15  26_dermatitis_perioral dermatitis_perioral_der...\n",
      "27     27     12             27_dry spot_spot_spot dry_dry spot dry\n",
      "28     28     11  28_dry pretty dry_incredibly dry_incredibly_dr...\n",
      "29     29     15                     29_eczema hand_eczema_arm_hand\n",
      "                 Cluster\n",
      "skin                  98\n",
      "acne                  86\n",
      "eczema                86\n",
      "redness               86\n",
      "dry                   47\n",
      "rosacea               35\n",
      "flaky                 35\n",
      "acne prone skin       33\n",
      "dry patch             33\n",
      "dry skin              26\n",
      "sensitive             22\n",
      "itchy                 22\n",
      "crack                 22\n",
      "pore                  21\n",
      "irritation            20\n",
      "moisture              20\n",
      "winter                19\n",
      "red                   18\n",
      "dryness               18\n",
      "hand                  17\n",
      "break                 17\n",
      "dermatitis            15\n",
      "eczema hand           15\n",
      "moisturizer           15\n",
      "acne prone            15\n",
      "rash                  12\n",
      "dry spot              12\n",
      "dry pretty            11\n",
      "             Cluster       L3 Cluster Phrase\n",
      "0               acne              treat acne\n",
      "1             eczema             have eczema\n",
      "3            dryness     helped with dryness\n",
      "4               hand          very dry hands\n",
      "5                dry                very dry\n",
      "6          sensitive           dry sensitive\n",
      "7        eczema hand      eczema on my hands\n",
      "8            rosacea            have rosacea\n",
      "9            redness          reduce redness\n",
      "10   acne prone skin         acne prone skin\n",
      "16        acne prone              acne prone\n",
      "22        dry pretty              pretty dry\n",
      "27         dry patch             dry patches\n",
      "29              skin          eas on my skin\n",
      "30        dermatitis     perioral dermatitis\n",
      "31          moisture       locks in moisture\n",
      "35          dry spot               dry spots\n",
      "36          dry skin        skin is very dry\n",
      "41             itchy         wintery itching\n",
      "43            winter  really dry winter skin\n",
      "50               red   Made my skin very red\n",
      "61             flaky          dry flaky skin\n",
      "63             crack            cracked skin\n",
      "109      moisturizer     ultra moisturizing!\n",
      "128             pore          clogs my pores\n",
      "129       irritation        skin irritations\n",
      "170             rash           horrible rash\n",
      "374            break           broke me out. \n",
      "\n",
      "Sentiment: Negative Aspect: Motivation\n",
      "   Topic  Count                                           Name\n",
      "0      0     60                      0_review_good_read_friend\n",
      "1      1     35                1_sample_get_get sample_receive\n",
      "2      2     24              2_moisturizer_skincare_skin_hyram\n",
      "3      3     40                            3_sale_size_get_buy\n",
      "4      4     17  4_sephora_recommend_sephora employee_employee\n",
      "             Cluster\n",
      "review            60\n",
      "sale              40\n",
      "sample            35\n",
      "moisturizer       24\n",
      "sephora           17\n",
      "       Cluster        L3 Cluster Phrase\n",
      "0         sale  got this with my points\n",
      "1  moisturizer      morning moisturizer\n",
      "3       review      reading the reviews\n",
      "8      sephora        went into Sephora\n",
      "9       sample     got this as a sample \n",
      "\n",
      "Sentiment: Negative Aspect: Competitor\n",
      "   Topic  Count                              Name\n",
      "0      0    102  0_cream_moisturizer_tatcha_drunk\n",
      "1      1     27      1_cerave_aveeno_dr_vanicream\n",
      "        Cluster\n",
      "cream       102\n",
      "cerave       27\n",
      "  Cluster L3 Cluster Phrase\n",
      "0   cream     steroid cream\n",
      "2  cerave            Cerave \n",
      "\n",
      "Sentiment: Negative Aspect: Allergy\n",
      "   Topic  Count                                               Name\n",
      "0      0     74   0_break_break break_break break break_make break\n",
      "1      1     64                            1_pimple_bump_peel_pore\n",
      "2      2     46             2_burn_sensation_tingle_burn sensation\n",
      "3      3     28                   3_pill_pille_pill pill_tend pill\n",
      "4      4     30                 4_irritate_skin_irritated_reaction\n",
      "5      5     25  5_breakout_breakout make_breakout make breakou...\n",
      "6      6     12                 6_skin break_skin_break_break skin\n",
      "            Cluster\n",
      "break            74\n",
      "pimple           64\n",
      "burn             46\n",
      "irritate         30\n",
      "pill             28\n",
      "breakout         25\n",
      "skin break       12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Cluster       L3 Cluster Phrase\n",
      "0       pimple          clogs my pores\n",
      "1         pill           tends to pill\n",
      "3     breakout       with no breakouts\n",
      "5         burn       burning sensation\n",
      "20    irritate       irritated my skin\n",
      "27       break    doesn't break me out\n",
      "36  skin break  make my skin break out \n",
      "\n",
      "Sentiment: Negative Aspect: Packaging\n",
      "   Topic  Count                       Name\n",
      "0      0     82          0_tube_tub_oz_jar\n",
      "1      1     51  1_size_last_product_month\n",
      "      Cluster\n",
      "tube       82\n",
      "size       51\n",
      "  Cluster   L3 Cluster Phrase\n",
      "0    tube  more than the tube\n",
      "1    size  lasts a few months \n",
      "\n",
      "Sentiment: Negative Aspect: Performance\n",
      "   Topic  Count                             Name\n",
      "0      0     71           0_skin_repair_dry_feel\n",
      "1      1     29  1_calm_calm skin_clog pore_clog\n",
      "2      2     24         2_last_product_time_long\n",
      "      Cluster\n",
      "skin       71\n",
      "calm       29\n",
      "last       24\n",
      "   Cluster  L3 Cluster Phrase\n",
      "0     skin     Healed my skin\n",
      "2     last  Lasts a long time\n",
      "12    calm      calms my skin \n",
      "\n",
      "Clustering done after 146.41 sec \n",
      "\n",
      "L2 Completed\n",
      "\n",
      "L1 Completed\n",
      "\n",
      "Excel File with 4 sheets is created.\n",
      "\n",
      "File name: P4_detailed_20230206v1.xlsx\n"
     ]
    }
   ],
   "source": [
    "l = detailed_output(df,map_dict=dP4,client='P4',take_sentiment=False,ng_range=(1,3),words_per_topic=5,words_to_remove=[]\n",
    "                    ,compress=False,create_exl=True,version='v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdfa2c",
   "metadata": {},
   "source": [
    "# top_n_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc793ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(['Review ID'],inplace=True)\n",
    "df = pd.read_excel('P4_detailed_20230201v1.xlsx')\n",
    "df = pd.merge(df,df1.loc[:,['Review ID','Review']],on='Review ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2150519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>L1 Cluster ID</th>\n",
       "      <th>L1 Cluster</th>\n",
       "      <th>L1 Phrase Count</th>\n",
       "      <th>L1 Review Count</th>\n",
       "      <th>L1 Rating (Phrase)</th>\n",
       "      <th>L1 Rating (Review)</th>\n",
       "      <th>L2 Cluster ID</th>\n",
       "      <th>L2 Cluster</th>\n",
       "      <th>L2 Phrase Count</th>\n",
       "      <th>...</th>\n",
       "      <th>L3 Review Count</th>\n",
       "      <th>L3 Rating (Review)</th>\n",
       "      <th>L3 Rating (Phrase)</th>\n",
       "      <th>L4 ID</th>\n",
       "      <th>L4 Phrases</th>\n",
       "      <th>Review ID</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>P4L4I17</td>\n",
       "      <td>dry skin</td>\n",
       "      <td>P4R1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>P+</td>\n",
       "      <td>Disastrous formula change.\\n\\nI've been using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>4.585714</td>\n",
       "      <td>4.608108</td>\n",
       "      <td>P4L4I16</td>\n",
       "      <td>sensitive skin</td>\n",
       "      <td>P4R1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>P+</td>\n",
       "      <td>Disastrous formula change.\\n\\nI've been using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>272</td>\n",
       "      <td>241</td>\n",
       "      <td>3.639706</td>\n",
       "      <td>3.668050</td>\n",
       "      <td>P4L2I9</td>\n",
       "      <td>Price</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>4.088235</td>\n",
       "      <td>P4L4I15</td>\n",
       "      <td>price on the 8oz tube by TWELVE DOLLARS</td>\n",
       "      <td>P4R1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>N+</td>\n",
       "      <td>Disastrous formula change.\\n\\nI've been using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I6</td>\n",
       "      <td>Odor</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>P4L4I6</td>\n",
       "      <td>scent was pleasant</td>\n",
       "      <td>P4R1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>P+</td>\n",
       "      <td>Disastrous formula change.\\n\\nI've been using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>272</td>\n",
       "      <td>241</td>\n",
       "      <td>3.639706</td>\n",
       "      <td>3.668050</td>\n",
       "      <td>P4L2I1</td>\n",
       "      <td>Ingredients</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>4.027778</td>\n",
       "      <td>3.975610</td>\n",
       "      <td>P4L4I1</td>\n",
       "      <td>Disastrous formula change</td>\n",
       "      <td>P4R1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>N+</td>\n",
       "      <td>Disastrous formula change.\\n\\nI've been using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I3</td>\n",
       "      <td>Application</td>\n",
       "      <td>213</td>\n",
       "      <td>177</td>\n",
       "      <td>3.516432</td>\n",
       "      <td>3.508475</td>\n",
       "      <td>P4L2I8</td>\n",
       "      <td>Application</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.564103</td>\n",
       "      <td>3.558140</td>\n",
       "      <td>P4L4I297</td>\n",
       "      <td>doesn’t feel the same</td>\n",
       "      <td>P4R69</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>N-</td>\n",
       "      <td>i think they reformulated\\n\\ni’ve used this be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I3</td>\n",
       "      <td>Application</td>\n",
       "      <td>213</td>\n",
       "      <td>177</td>\n",
       "      <td>3.516432</td>\n",
       "      <td>3.508475</td>\n",
       "      <td>P4L2I8</td>\n",
       "      <td>Application</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.564103</td>\n",
       "      <td>3.558140</td>\n",
       "      <td>P4L4I656</td>\n",
       "      <td>Why change a formula thats been a cult favorit...</td>\n",
       "      <td>P4R165</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>N-</td>\n",
       "      <td>formula change\\n\\nThis has been my ALL TIME FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I3</td>\n",
       "      <td>Application</td>\n",
       "      <td>213</td>\n",
       "      <td>177</td>\n",
       "      <td>3.516432</td>\n",
       "      <td>3.508475</td>\n",
       "      <td>P4L2I8</td>\n",
       "      <td>Application</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.564103</td>\n",
       "      <td>3.558140</td>\n",
       "      <td>P4L4I657</td>\n",
       "      <td>why fix something that’s not broken? I</td>\n",
       "      <td>P4R165</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>N-</td>\n",
       "      <td>formula change\\n\\nThis has been my ALL TIME FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I3</td>\n",
       "      <td>Application</td>\n",
       "      <td>213</td>\n",
       "      <td>177</td>\n",
       "      <td>3.516432</td>\n",
       "      <td>3.508475</td>\n",
       "      <td>P4L2I8</td>\n",
       "      <td>Application</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.564103</td>\n",
       "      <td>3.558140</td>\n",
       "      <td>P4L4I658</td>\n",
       "      <td>won’t be repurchasing unless they change it back</td>\n",
       "      <td>P4R165</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>N-</td>\n",
       "      <td>formula change\\n\\nThis has been my ALL TIME FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I3</td>\n",
       "      <td>Application</td>\n",
       "      <td>213</td>\n",
       "      <td>177</td>\n",
       "      <td>3.516432</td>\n",
       "      <td>3.508475</td>\n",
       "      <td>P4L2I8</td>\n",
       "      <td>Application</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.564103</td>\n",
       "      <td>3.558140</td>\n",
       "      <td>P4L4I2710</td>\n",
       "      <td>my dry climate</td>\n",
       "      <td>P4R905</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>N-</td>\n",
       "      <td>I was really excited to try this product and w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4430 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment L1 Cluster ID   L1 Cluster  L1 Phrase Count  L1 Review Count  \\\n",
       "0     Positive        P4L1I1      Product             1048             1012   \n",
       "1     Positive        P4L1I1      Product             1048             1012   \n",
       "2     Negative        P4L1I1      Product              272              241   \n",
       "3     Positive        P4L1I1      Product             1048             1012   \n",
       "4     Negative        P4L1I1      Product              272              241   \n",
       "...        ...           ...          ...              ...              ...   \n",
       "4425  Negative        P4L1I3  Application              213              177   \n",
       "4426  Negative        P4L1I3  Application              213              177   \n",
       "4427  Negative        P4L1I3  Application              213              177   \n",
       "4428  Negative        P4L1I3  Application              213              177   \n",
       "4429  Negative        P4L1I3  Application              213              177   \n",
       "\n",
       "      L1 Rating (Phrase)  L1 Rating (Review) L2 Cluster ID   L2 Cluster  \\\n",
       "0               4.457061            4.458004       P4L2I10    Skin_type   \n",
       "1               4.457061            4.458004       P4L2I10    Skin_type   \n",
       "2               3.639706            3.668050        P4L2I9        Price   \n",
       "3               4.457061            4.458004        P4L2I6         Odor   \n",
       "4               3.639706            3.668050        P4L2I1  Ingredients   \n",
       "...                  ...                 ...           ...          ...   \n",
       "4425            3.516432            3.508475        P4L2I8  Application   \n",
       "4426            3.516432            3.508475        P4L2I8  Application   \n",
       "4427            3.516432            3.508475        P4L2I8  Application   \n",
       "4428            3.516432            3.508475        P4L2I8  Application   \n",
       "4429            3.516432            3.508475        P4L2I8  Application   \n",
       "\n",
       "      L2 Phrase Count  ...  L3 Review Count  L3 Rating (Review)  \\\n",
       "0                 331  ...              117            4.384615   \n",
       "1                 331  ...               70            4.585714   \n",
       "2                  34  ...               32            4.031250   \n",
       "3                  91  ...               57            4.333333   \n",
       "4                  41  ...               36            4.027778   \n",
       "...               ...  ...              ...                 ...   \n",
       "4425               60  ...               39            3.564103   \n",
       "4426               60  ...               39            3.564103   \n",
       "4427               60  ...               39            3.564103   \n",
       "4428               60  ...               39            3.564103   \n",
       "4429               60  ...               39            3.564103   \n",
       "\n",
       "      L3 Rating (Phrase)      L4 ID  \\\n",
       "0               4.366667    P4L4I17   \n",
       "1               4.608108    P4L4I16   \n",
       "2               4.088235    P4L4I15   \n",
       "3               4.333333     P4L4I6   \n",
       "4               3.975610     P4L4I1   \n",
       "...                  ...        ...   \n",
       "4425            3.558140   P4L4I297   \n",
       "4426            3.558140   P4L4I656   \n",
       "4427            3.558140   P4L4I657   \n",
       "4428            3.558140   P4L4I658   \n",
       "4429            3.558140  P4L4I2710   \n",
       "\n",
       "                                             L4 Phrases Review ID  \\\n",
       "0                                              dry skin      P4R1   \n",
       "1                                        sensitive skin      P4R1   \n",
       "2               price on the 8oz tube by TWELVE DOLLARS      P4R1   \n",
       "3                                    scent was pleasant      P4R1   \n",
       "4                             Disastrous formula change      P4R1   \n",
       "...                                                 ...       ...   \n",
       "4425                              doesn’t feel the same     P4R69   \n",
       "4426  Why change a formula thats been a cult favorit...    P4R165   \n",
       "4427             why fix something that’s not broken? I    P4R165   \n",
       "4428   won’t be repurchasing unless they change it back    P4R165   \n",
       "4429                                     my dry climate    P4R905   \n",
       "\n",
       "      Review Rating       Date  Flag  \\\n",
       "0                 1 2022-11-18    P+   \n",
       "1                 1 2022-11-18    P+   \n",
       "2                 1 2022-11-18    N+   \n",
       "3                 1 2022-11-18    P+   \n",
       "4                 1 2022-11-18    N+   \n",
       "...             ...        ...   ...   \n",
       "4425              5 2022-06-09    N-   \n",
       "4426              4 2022-02-05    N-   \n",
       "4427              4 2022-02-05    N-   \n",
       "4428              4 2022-02-05    N-   \n",
       "4429              3 2019-12-24    N-   \n",
       "\n",
       "                                                 Review  \n",
       "0     Disastrous formula change.\\n\\nI've been using ...  \n",
       "1     Disastrous formula change.\\n\\nI've been using ...  \n",
       "2     Disastrous formula change.\\n\\nI've been using ...  \n",
       "3     Disastrous formula change.\\n\\nI've been using ...  \n",
       "4     Disastrous formula change.\\n\\nI've been using ...  \n",
       "...                                                 ...  \n",
       "4425  i think they reformulated\\n\\ni’ve used this be...  \n",
       "4426  formula change\\n\\nThis has been my ALL TIME FA...  \n",
       "4427  formula change\\n\\nThis has been my ALL TIME FA...  \n",
       "4428  formula change\\n\\nThis has been my ALL TIME FA...  \n",
       "4429  I was really excited to try this product and w...  \n",
       "\n",
       "[4430 rows x 27 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49bc6774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def top_n_reviews_l3(df,n=5,year_duration=2):\n",
    "    #Filtering with year duration\n",
    "    df1= df[df['Date']>=pd.to_datetime(date.today()-relativedelta(years=year_duration))]\n",
    "    #Calculating the similarity of each phrase wrt the most common phrase\n",
    "    df1['sim']=''\n",
    "    for id in df1['L3 Cluster ID'].unique():\n",
    "        for idx in df1[df1['L3 Cluster ID']==id].index:\n",
    "            df1['sim'][idx] = jellyfish.levenshtein_distance(df1['L3 Cluster Phrase'][idx],df1['Review'][idx])\n",
    "            \n",
    "    #Creating the top_n_reviews dataframe\n",
    "    df2 = pd.DataFrame(columns=df1.columns)\n",
    "    for idx in df1['L3 Cluster ID'].unique():\n",
    "        s = len(df1[df1['L3 Cluster ID']==idx])\n",
    "        #Appending the most recent phrase\n",
    "        df2 = df2.append(df1[df1['L3 Cluster ID']==idx].sort_values(['Date'],ascending=False).iloc[0])\n",
    "        #Appending rest n-1 phrases in sorted order of similarity\n",
    "        df3 = df1[(df1['L3 Cluster ID']==idx)&(df1['Review ID']!=df2.iloc[-1]['Review ID'])].sort_values(['sim'])\n",
    "        df3.drop_duplicates(['L3 Cluster ID','Review ID'],keep='first',inplace=True)\n",
    "        df2 = df2.append(df3.iloc[:min(s,n-1)])\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fd983d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = top_n_reviews_l3(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e40770e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('P4_L3_top_5_20230202v1.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb988264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def top_n_reviews_l2(df,client,n=4,version='v1',create_exl=False):\n",
    "    df2 = pd.DataFrame(columns=df.columns)\n",
    "    for idx in df['L2 Cluster ID'].unique():\n",
    "        for senti in ['Positive','Negative']:\n",
    "            df1 = df[(df['L2 Cluster ID']==idx)&(df['Sentiment']==senti)].sort_values(['L3 Review Count','Date'],ascending=False)\n",
    "            if len(df1)==0:\n",
    "                continue\n",
    "            df2 = df2.append(df1.iloc[0])\n",
    "            rid,cid = [],[]\n",
    "            rid.append(df1.iloc[0]['Review ID'])\n",
    "            cid.append(df1.iloc[0]['L3 Cluster ID'])\n",
    "            cnt=n-1\n",
    "            while(cnt):\n",
    "                try:\n",
    "                    df2 = df2.append(df1[(~df1['Review ID'].isin(rid))&(~df1['L3 Cluster ID'].isin(cid))].iloc[0])\n",
    "                    rid.append(df2.iloc[-1]['Review ID'])\n",
    "                    cid.append(df2.iloc[-1]['L3 Cluster ID'])\n",
    "                    cnt-=1\n",
    "                except:\n",
    "                    break\n",
    "    if create_exl:\n",
    "        name = client+\"_top_\"+str(n)+\"_reviews_l2_\"+date.today().strftime('%Y%m%d')+version+\".xlsx\"\n",
    "        df2.to_excel(name,index=False)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bea9a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>L1 Cluster ID</th>\n",
       "      <th>L1 Cluster</th>\n",
       "      <th>L1 Phrase Count</th>\n",
       "      <th>L1 Review Count</th>\n",
       "      <th>L1 Rating (Phrase)</th>\n",
       "      <th>L1 Rating (Review)</th>\n",
       "      <th>L2 Cluster ID</th>\n",
       "      <th>L2 Cluster</th>\n",
       "      <th>L2 Phrase Count</th>\n",
       "      <th>...</th>\n",
       "      <th>L3 Review Count</th>\n",
       "      <th>L3 Rating (Review)</th>\n",
       "      <th>L3 Rating (Phrase)</th>\n",
       "      <th>L4 ID</th>\n",
       "      <th>L4 Phrases</th>\n",
       "      <th>Review ID</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>P4L4I17</td>\n",
       "      <td>dry skin</td>\n",
       "      <td>P4R1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>P+</td>\n",
       "      <td>Disastrous formula change.\\n\\nI've been using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>4.585714</td>\n",
       "      <td>4.608108</td>\n",
       "      <td>P4L4I58</td>\n",
       "      <td>super sensitive skin</td>\n",
       "      <td>P4R6</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>P+</td>\n",
       "      <td>Worth it! Calms rosacea\\n\\nI have rosacea and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>4.729730</td>\n",
       "      <td>4.736842</td>\n",
       "      <td>P4L4I598</td>\n",
       "      <td>normal to oily skin</td>\n",
       "      <td>P4R142</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>P+</td>\n",
       "      <td>Hydration without the greasiness\\n\\nLove this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>4.484848</td>\n",
       "      <td>P4L4I117</td>\n",
       "      <td>normal to dry skin</td>\n",
       "      <td>P4R21</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>P+</td>\n",
       "      <td>A MUST Have\\n\\nNo redness no breakouts . I hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>272</td>\n",
       "      <td>241</td>\n",
       "      <td>3.639706</td>\n",
       "      <td>3.668050</td>\n",
       "      <td>P4L2I10</td>\n",
       "      <td>Skin_type</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>P4L4I231</td>\n",
       "      <td>not for sensitive skin</td>\n",
       "      <td>P4R51</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>N-</td>\n",
       "      <td>Irritated my skin :/\\n\\nI had been wanting to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I12</td>\n",
       "      <td>Motivation</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>4.290323</td>\n",
       "      <td>P4L4I49</td>\n",
       "      <td>calm it down a bit</td>\n",
       "      <td>P4R6</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>P+</td>\n",
       "      <td>Worth it! Calms rosacea\\n\\nI have rosacea and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>1048</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.457061</td>\n",
       "      <td>4.458004</td>\n",
       "      <td>P4L2I12</td>\n",
       "      <td>Motivation</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>P4L4I478</td>\n",
       "      <td>reading the reviews</td>\n",
       "      <td>P4R108</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>P+</td>\n",
       "      <td>not moisturizing\\n\\nI bought this after seeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I1</td>\n",
       "      <td>Product</td>\n",
       "      <td>272</td>\n",
       "      <td>241</td>\n",
       "      <td>3.639706</td>\n",
       "      <td>3.668050</td>\n",
       "      <td>P4L2I12</td>\n",
       "      <td>Motivation</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>P4L4I244</td>\n",
       "      <td>recommended by one of Sephora's</td>\n",
       "      <td>P4R55</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>N-</td>\n",
       "      <td>Wrong for dry skin\\n\\nNot the products fault b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>Positive</td>\n",
       "      <td>P4L1I2</td>\n",
       "      <td>Emotional</td>\n",
       "      <td>486</td>\n",
       "      <td>458</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>4.446507</td>\n",
       "      <td>P4L2I13</td>\n",
       "      <td>Competitor</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.974359</td>\n",
       "      <td>4.088889</td>\n",
       "      <td>P4L4I165</td>\n",
       "      <td>retinol every other day</td>\n",
       "      <td>P4R35</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>P-</td>\n",
       "      <td>disappointed\\n\\nI use retinol every other day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>Negative</td>\n",
       "      <td>P4L1I2</td>\n",
       "      <td>Emotional</td>\n",
       "      <td>180</td>\n",
       "      <td>152</td>\n",
       "      <td>3.994444</td>\n",
       "      <td>3.953947</td>\n",
       "      <td>P4L2I13</td>\n",
       "      <td>Competitor</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>4.177419</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>P4L4I23</td>\n",
       "      <td>l'occitaine cream</td>\n",
       "      <td>P4R2</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>N+</td>\n",
       "      <td>Best by far\\n\\nI got this while it was on sale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment L1 Cluster ID L1 Cluster L1 Phrase Count L1 Review Count  \\\n",
       "0     Positive        P4L1I1    Product            1048            1012   \n",
       "456   Positive        P4L1I1    Product            1048            1012   \n",
       "722   Positive        P4L1I1    Product            1048            1012   \n",
       "863   Positive        P4L1I1    Product            1048            1012   \n",
       "1248  Negative        P4L1I1    Product             272             241   \n",
       "...        ...           ...        ...             ...             ...   \n",
       "459   Positive        P4L1I1    Product            1048            1012   \n",
       "2379  Positive        P4L1I1    Product            1048            1012   \n",
       "1359  Negative        P4L1I1    Product             272             241   \n",
       "4027  Positive        P4L1I2  Emotional             486             458   \n",
       "2625  Negative        P4L1I2  Emotional             180             152   \n",
       "\n",
       "      L1 Rating (Phrase)  L1 Rating (Review) L2 Cluster ID  L2 Cluster  \\\n",
       "0               4.457061            4.458004       P4L2I10   Skin_type   \n",
       "456             4.457061            4.458004       P4L2I10   Skin_type   \n",
       "722             4.457061            4.458004       P4L2I10   Skin_type   \n",
       "863             4.457061            4.458004       P4L2I10   Skin_type   \n",
       "1248            3.639706            3.668050       P4L2I10   Skin_type   \n",
       "...                  ...                 ...           ...         ...   \n",
       "459             4.457061            4.458004       P4L2I12  Motivation   \n",
       "2379            4.457061            4.458004       P4L2I12  Motivation   \n",
       "1359            3.639706            3.668050       P4L2I12  Motivation   \n",
       "4027            4.444444            4.446507       P4L2I13  Competitor   \n",
       "2625            3.994444            3.953947       P4L2I13  Competitor   \n",
       "\n",
       "     L2 Phrase Count  ... L3 Review Count  L3 Rating (Review)  \\\n",
       "0                331  ...             117            4.384615   \n",
       "456              331  ...              70            4.585714   \n",
       "722              331  ...              37            4.729730   \n",
       "863              331  ...              32            4.468750   \n",
       "1248              66  ...              25            3.000000   \n",
       "...              ...  ...             ...                 ...   \n",
       "459              161  ...              30            4.300000   \n",
       "2379             161  ...              30            4.166667   \n",
       "1359              15  ...              15            3.133333   \n",
       "4027              45  ...              39            3.974359   \n",
       "2625              84  ...              62            4.177419   \n",
       "\n",
       "      L3 Rating (Phrase)     L4 ID                       L4 Phrases Review ID  \\\n",
       "0               4.366667   P4L4I17                         dry skin      P4R1   \n",
       "456             4.608108   P4L4I58             super sensitive skin      P4R6   \n",
       "722             4.736842  P4L4I598              normal to oily skin    P4R142   \n",
       "863             4.484848  P4L4I117               normal to dry skin     P4R21   \n",
       "1248            3.000000  P4L4I231           not for sensitive skin     P4R51   \n",
       "...                  ...       ...                              ...       ...   \n",
       "459             4.290323   P4L4I49               calm it down a bit      P4R6   \n",
       "2379            4.166667  P4L4I478              reading the reviews    P4R108   \n",
       "1359            3.133333  P4L4I244  recommended by one of Sephora's     P4R55   \n",
       "4027            4.088889  P4L4I165          retinol every other day     P4R35   \n",
       "2625            4.166667   P4L4I23                l'occitaine cream      P4R2   \n",
       "\n",
       "     Review Rating       Date  Flag  \\\n",
       "0                1 2022-11-18    P+   \n",
       "456              5 2022-10-23    P+   \n",
       "722              5 2022-03-02    P+   \n",
       "863              5 2022-09-20    P+   \n",
       "1248             1 2022-07-13    N-   \n",
       "...            ...        ...   ...   \n",
       "459              5 2022-10-23    P+   \n",
       "2379             1 2022-04-07    P+   \n",
       "1359             5 2022-07-01    N-   \n",
       "4027             5 2022-08-15    P-   \n",
       "2625             5 2022-11-18    N+   \n",
       "\n",
       "                                                 Review  \n",
       "0     Disastrous formula change.\\n\\nI've been using ...  \n",
       "456   Worth it! Calms rosacea\\n\\nI have rosacea and ...  \n",
       "722   Hydration without the greasiness\\n\\nLove this ...  \n",
       "863   A MUST Have\\n\\nNo redness no breakouts . I hav...  \n",
       "1248  Irritated my skin :/\\n\\nI had been wanting to ...  \n",
       "...                                                 ...  \n",
       "459   Worth it! Calms rosacea\\n\\nI have rosacea and ...  \n",
       "2379  not moisturizing\\n\\nI bought this after seeing...  \n",
       "1359  Wrong for dry skin\\n\\nNot the products fault b...  \n",
       "4027  disappointed\\n\\nI use retinol every other day ...  \n",
       "2625  Best by far\\n\\nI got this while it was on sale...  \n",
       "\n",
       "[74 rows x 27 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_reviews_l2(df,client='P4',create_exl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413f5a0",
   "metadata": {},
   "source": [
    "# timely report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "88235e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timely_report(df,client,version='v1',create_exl=False):\n",
    "    #dataframe processing\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Month']=df['Date'].apply(lambda x:x.month)\n",
    "    df['Year']=df['Date'].apply(lambda x:x.year)\n",
    "    try:\n",
    "        df['Rating'] = df[\"Rating\"].apply(lambda x : int(x.split()[0]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Extracting the months and years from date range\n",
    "    mn = df['Date'].min()\n",
    "    mx = df['Date'].max()\n",
    "    x = pd.date_range(mn,mx,freq='MS')\n",
    "    d1 = pd.DataFrame(columns=['Month','Year','Review Count','Avg Review Rating'])\n",
    "    d1['Month'] = x.month\n",
    "    d1['Year'] = x.year\n",
    "    d2 = d1.copy()\n",
    "    \n",
    "    def fill(df,report,period):\n",
    "        #This function will fill the values in report\n",
    "        if period=='monthly':\n",
    "            a = 'Month'\n",
    "        elif period=='quarterly':\n",
    "            a = 'Quarter'\n",
    "        else:\n",
    "            a = 'week_of'\n",
    "            for i in report.index:\n",
    "                report['Review Count'][i] = len(df[(df[a]==report[a][i])])\n",
    "                report['Avg Review Rating'][i] = round(df[(df[a]==report[a][i])]['Rating'].mean(),2)\n",
    "            return report\n",
    "        \n",
    "        for i in report.index:\n",
    "            report['Review Count'][i] = len(df[(df[a]==report[a][i])&(df['Year']==report['Year'][i])])\n",
    "            report['Avg Review Rating'][i] = round(df[(df[a]==report[a][i])&(df['Year']==report['Year'][i])]['Rating'].mean(),2)\n",
    "        return report\n",
    "    \n",
    "    d1 = fill(df,d1,period='monthly')\n",
    "    \n",
    "    df['Quarter'] = ''\n",
    "    d2['Quarter'] = ''\n",
    "    #Inserting Quarter Value corresponding to month in report and dataframe\n",
    "    for x in [df,d2]:\n",
    "        for i in x.index:\n",
    "            if x['Month'][i]<=4:\n",
    "                x['Quarter'][i] = 1\n",
    "            elif x['Month'][i]>4 and x['Month'][i]<=8:\n",
    "                x['Quarter'][i] = 2\n",
    "            else:\n",
    "                x['Quarter'][i] = 3\n",
    "    d2.drop_duplicates(['Quarter','Year'],inplace=True)        \n",
    "    d2 = fill(df,d2,period='quarterly')\n",
    "    d2 = d2.loc[:,['Quarter','Year','Review Count','Avg Review Rating']]\n",
    "        \n",
    "    df['week_of']=''\n",
    "    d3 = pd.DataFrame(columns=['week_of','Review Count','Avg Review Rating'])\n",
    "    d3['Date'] = pd.date_range(df['Date'].min(),df['Date'].max())\n",
    "    #Inserting week corresponding to date in report and dataframe\n",
    "    for x in [df,d3]:\n",
    "        for i in x.index:\n",
    "            y = x['Date'][i].weekday()\n",
    "            if y==6:\n",
    "                x['week_of'][i] = x['Date'][i]\n",
    "            else:\n",
    "                x['week_of'][i] = (x['Date'][i]-timedelta(y+1))\n",
    "    d3.drop(['Date'],1,inplace=True)\n",
    "    d3.drop_duplicates(['week_of'],inplace=True)\n",
    "    d3 = fill(df,d3,period='weekly')\n",
    "    \n",
    "    for report in [d1,d2,d3]:\n",
    "        report.fillna(0,inplace=True) #filling null values with 0\n",
    "        \n",
    "    #Creating the excel file with different reports present in different tabs\n",
    "    if create_exl:\n",
    "        name = client+\"_report_\"+date.today().strftime('%Y%m%d')+version+\".xlsx\"\n",
    "        path = r\"{fname}\".format(fname=name)\n",
    "        with pd.ExcelWriter(path) as engine:\n",
    "            d2.to_excel(excel_writer=engine,sheet_name=client+'_Quarterly_'+date.today().strftime('%Y%m%d'),index=False)\n",
    "            d1.to_excel(excel_writer=engine,sheet_name=client+'_Monthly_'+date.today().strftime('%Y%m%d'),index=False)\n",
    "            d3.to_excel(excel_writer=engine,sheet_name=client+'_Weekly_'+date.today().strftime('%Y%m%d'),index=False)\n",
    "        print(\"Excel File with 3 sheets is created.\\n\")\n",
    "        print(\"File name:\",name)\n",
    "    dfs = [d1,d2,d3]\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ab07bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('P1_Estee Lauder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "34450f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ZipFile.__del__ at 0x00000233EBCC0AF0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kshit\\anaconda3\\envs\\tf\\lib\\zipfile.py\", line 1821, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\kshit\\anaconda3\\envs\\tf\\lib\\zipfile.py\", line 1838, in close\n",
      "    self.fp.seek(self.start_dir)\n",
      "ValueError: seek of closed file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel File with 3 sheets is created.\n",
      "\n",
      "File name: P1_report_20230203v1.xlsx\n"
     ]
    }
   ],
   "source": [
    "l = timely_report(df,client='P1',create_exl=True)#.to_excel('P1_monthly_20230203.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
